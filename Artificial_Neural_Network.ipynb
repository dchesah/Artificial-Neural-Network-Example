{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2658472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '##'\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu ## Using my system's gpu to train this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7fece6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8d095c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f8d07aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import some basic libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20cc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "669e5b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('E:\\\\') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ef8b58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ce275510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e220dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataset into dependent and independent components\n",
    "\n",
    "X= dataset.iloc[:, 3:13] ## We drop a few columns that we think/know won't help our model\n",
    "y=dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d93f567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>757</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>177528.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>550</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70399.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>148586.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>176791.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>720</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39925.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>651</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>165901.59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23054.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "4788          757     Spain  Female   44       9       0.00              2   \n",
       "4193          550     Spain    Male   45       0       0.00              2   \n",
       "1100          850    France  Female   39       2  148586.64              1   \n",
       "8976          720    France    Male   29       2       0.00              2   \n",
       "4741          651    France    Male   45       2  165901.59              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "4788          1               0        177528.92  \n",
       "4193          0               1         70399.71  \n",
       "1100          1               1        176791.27  \n",
       "8976          1               0         39925.52  \n",
       "4741          1               0         23054.51  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f54b6fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615     1\n",
       "773     0\n",
       "8659    0\n",
       "4528    0\n",
       "2864    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0e1de3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature Engineering\n",
    "\n",
    "geography = pd.get_dummies(X['Geography'], drop_first = True)\n",
    "gender = pd.get_dummies(X['Gender'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f7db7228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "...    ...\n",
       "9995     1\n",
       "9996     1\n",
       "9997     0\n",
       "9998     1\n",
       "9999     0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9e915f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Concatenate these variables with the dataframe\n",
    "\n",
    "X=X.drop(['Geography', 'Gender'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "26009286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  \n",
       "0                  1        101348.88  \n",
       "1                  1        112542.58  \n",
       "2                  0        113931.57  \n",
       "3                  0         93826.63  \n",
       "4                  1         79084.10  \n",
       "...              ...              ...  \n",
       "9995               0         96270.64  \n",
       "9996               1        101699.77  \n",
       "9997               1         42085.58  \n",
       "9998               0         92888.52  \n",
       "9999               0         38190.78  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "39f096ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,geography, gender], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "37b2f1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>850</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>122311.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19482.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7967</th>\n",
       "      <td>583</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>112701.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29213.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>720</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>97042.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133516.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>717</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>128206.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54272.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>680</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>140007.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31714.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "180           850   45       2  122311.21              1          1   \n",
       "7967          583   40       9  112701.04              1          0   \n",
       "4345          720   46       3   97042.60              1          1   \n",
       "9150          717   28       4  128206.79              1          1   \n",
       "3932          680   23       5  140007.19              1          0   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "180                1         19482.50        0      1     0  \n",
       "7967               0         29213.63        0      0     1  \n",
       "4345               1        133516.51        1      0     1  \n",
       "9150               1         54272.12        0      0     1  \n",
       "3932               1         31714.08        0      0     1  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0aa6db9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Germany            0\n",
       "Spain              0\n",
       "Male               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c00b5415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "62644b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting the dataset into Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "cc1865fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b2480de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOte, with ANN, feature scaling is almost imperative. Most algorithms that require gradient descent or some distance band will \n",
    "## require scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "816630d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d295cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b0c00e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train) ## To avoid data leakage, we do fit_trainsform for the train set and only fit for the test set\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "17c3e121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55498354, -0.37147055,  1.03768102, ...,  1.73205081,\n",
       "        -0.57965968, -1.09748077],\n",
       "       [ 0.48605107,  0.48924515,  1.7300742 , ...,  1.73205081,\n",
       "        -0.57965968,  0.9111777 ],\n",
       "       [-0.31791625, -0.94528101, -0.69330195, ..., -0.57735027,\n",
       "        -0.57965968, -1.09748077],\n",
       "       ...,\n",
       "       [-0.67867082,  1.541231  ,  1.7300742 , ..., -0.57735027,\n",
       "        -0.57965968,  0.9111777 ],\n",
       "       [-1.66816907, -0.75401086,  0.69148442, ..., -0.57735027,\n",
       "        -0.57965968, -1.09748077],\n",
       "       [ 0.68188927,  1.92377131, -0.34710536, ..., -0.57735027,\n",
       "        -0.57965968, -1.09748077]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4265ab83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59141595, -0.66663363, -0.70673342, ..., -0.58427872,\n",
       "        -0.55039222, -1.09003844],\n",
       "       [ 0.48066571,  1.59569771, -0.362573  , ..., -0.58427872,\n",
       "         1.81688615, -1.09003844],\n",
       "       [ 2.1098094 , -0.38384222, -1.39505426, ..., -0.58427872,\n",
       "        -0.55039222, -1.09003844],\n",
       "       ...,\n",
       "       [-0.30762963, -0.57236983,  1.3582291 , ..., -0.58427872,\n",
       "        -0.55039222, -1.09003844],\n",
       "       [-1.01184013, -0.00678699, -1.39505426, ..., -0.58427872,\n",
       "         1.81688615, -1.09003844],\n",
       "       [-1.61094458, -0.66663363, -0.362573  , ..., -0.58427872,\n",
       "        -0.55039222,  0.91739884]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dd9a850d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "36b7e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fb2de658",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We now create the ANN. We will use Tensorflow (open source created by Google) and keras (created by apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b2892c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ReLU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2384f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANN initialization\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "3126a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We add our layers by starting with the input layer and the corresponding activation function\n",
    "\n",
    "classifier.add(Dense(units=11, activation = 'relu')) ## 11 inputs neurons here each for the number of input features in our dataset\n",
    "\n",
    "#classifier.add(Dropout(.2))  ## This will randomly select some nodes to be dropped out with a probability of 20% during training\n",
    "\n",
    "## First hidden layer\n",
    "\n",
    "classifier.add(Dense(units=7, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dropout(.3))\n",
    "##Second hidden layer\n",
    "\n",
    "classifier.add(Dense(units=6, activation = 'relu'))\n",
    "\n",
    "#classifier.add(Dropout(.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "973f85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the output layer\n",
    "\n",
    "classifier.add(Dense(units=1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3624a6a",
   "metadata": {},
   "source": [
    "# we can go ahead and use the adam optimizer which has a default learning rate of .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "58d9e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics =['accuracy'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "55da3ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If we want to use our own learning rate, we can define it as seen below:\n",
    "import tensorflow\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2697c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "04abd99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8418 - val_loss: 0.3539 - val_accuracy: 0.8622\n",
      "Epoch 2/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8431 - val_loss: 0.3562 - val_accuracy: 0.8538\n",
      "Epoch 3/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8431 - val_loss: 0.3549 - val_accuracy: 0.8569\n",
      "Epoch 4/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8419 - val_loss: 0.3570 - val_accuracy: 0.8557\n",
      "Epoch 5/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8410 - val_loss: 0.3551 - val_accuracy: 0.8557\n",
      "Epoch 6/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8446 - val_loss: 0.3537 - val_accuracy: 0.8535\n",
      "Epoch 7/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8375 - val_loss: 0.3556 - val_accuracy: 0.8527\n",
      "Epoch 8/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8433 - val_loss: 0.3677 - val_accuracy: 0.8550\n",
      "Epoch 9/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8472 - val_loss: 0.3678 - val_accuracy: 0.8595\n",
      "Epoch 10/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8449 - val_loss: 0.3607 - val_accuracy: 0.8546\n",
      "Epoch 11/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8419 - val_loss: 0.3612 - val_accuracy: 0.8610\n",
      "Epoch 12/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8464 - val_loss: 0.3579 - val_accuracy: 0.8584\n",
      "Epoch 13/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8403 - val_loss: 0.3600 - val_accuracy: 0.8531\n",
      "Epoch 14/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8419 - val_loss: 0.3604 - val_accuracy: 0.8478\n",
      "Epoch 15/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8457 - val_loss: 0.3641 - val_accuracy: 0.8557\n",
      "Epoch 16/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8459 - val_loss: 0.3646 - val_accuracy: 0.8576\n",
      "Epoch 17/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8461 - val_loss: 0.3644 - val_accuracy: 0.8603\n",
      "Epoch 18/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8466 - val_loss: 0.3663 - val_accuracy: 0.8531\n",
      "Epoch 19/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8419 - val_loss: 0.3598 - val_accuracy: 0.8383\n",
      "Epoch 20/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8442 - val_loss: 0.3547 - val_accuracy: 0.8595\n",
      "Epoch 21/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8436 - val_loss: 0.3827 - val_accuracy: 0.8523\n",
      "Epoch 22/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8451 - val_loss: 0.3656 - val_accuracy: 0.8554\n",
      "Epoch 23/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8468 - val_loss: 0.3552 - val_accuracy: 0.8542\n",
      "Epoch 24/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8462 - val_loss: 0.3626 - val_accuracy: 0.8580\n",
      "Epoch 25/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8474 - val_loss: 0.3628 - val_accuracy: 0.8535\n",
      "Epoch 26/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8498 - val_loss: 0.3599 - val_accuracy: 0.8576\n",
      "Epoch 27/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8438 - val_loss: 0.3667 - val_accuracy: 0.8213\n",
      "Epoch 28/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8477 - val_loss: 0.3650 - val_accuracy: 0.8610\n",
      "Epoch 29/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8414 - val_loss: 0.3598 - val_accuracy: 0.8580\n",
      "Epoch 30/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8433 - val_loss: 0.3651 - val_accuracy: 0.8516\n",
      "Epoch 31/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8405 - val_loss: 0.3598 - val_accuracy: 0.8519\n",
      "Epoch 32/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8447 - val_loss: 0.3576 - val_accuracy: 0.8501\n",
      "Epoch 33/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8421 - val_loss: 0.3552 - val_accuracy: 0.8580\n",
      "Epoch 34/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8464 - val_loss: 0.3585 - val_accuracy: 0.8599\n",
      "Epoch 35/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8487 - val_loss: 0.3692 - val_accuracy: 0.8614\n",
      "Epoch 36/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8496 - val_loss: 0.3601 - val_accuracy: 0.8573\n",
      "Epoch 37/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8520 - val_loss: 0.3568 - val_accuracy: 0.8607\n",
      "Epoch 38/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8419 - val_loss: 0.3604 - val_accuracy: 0.8584\n",
      "Epoch 39/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8457 - val_loss: 0.3529 - val_accuracy: 0.8588\n",
      "Epoch 40/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8492 - val_loss: 0.3668 - val_accuracy: 0.8550\n",
      "Epoch 41/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8442 - val_loss: 0.3589 - val_accuracy: 0.8573\n",
      "Epoch 42/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8479 - val_loss: 0.3581 - val_accuracy: 0.8565\n",
      "Epoch 43/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8464 - val_loss: 0.3726 - val_accuracy: 0.8580\n",
      "Epoch 44/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8444 - val_loss: 0.3553 - val_accuracy: 0.8538\n",
      "Epoch 45/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8481 - val_loss: 0.3568 - val_accuracy: 0.8557\n",
      "Epoch 46/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8427 - val_loss: 0.3599 - val_accuracy: 0.8603\n",
      "Epoch 47/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8457 - val_loss: 0.3587 - val_accuracy: 0.8622\n",
      "Epoch 48/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8472 - val_loss: 0.3538 - val_accuracy: 0.8584\n",
      "Epoch 49/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8447 - val_loss: 0.3558 - val_accuracy: 0.8595\n",
      "Epoch 50/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8414 - val_loss: 0.3622 - val_accuracy: 0.8463\n",
      "Epoch 51/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8468 - val_loss: 0.3665 - val_accuracy: 0.8516\n",
      "Epoch 52/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8390 - val_loss: 0.3594 - val_accuracy: 0.8485\n",
      "Epoch 53/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8399 - val_loss: 0.3588 - val_accuracy: 0.8527\n",
      "Epoch 54/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8455 - val_loss: 0.3697 - val_accuracy: 0.8504\n",
      "Epoch 55/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8408 - val_loss: 0.3572 - val_accuracy: 0.8519\n",
      "Epoch 56/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8434 - val_loss: 0.3587 - val_accuracy: 0.8474\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8472 - val_loss: 0.3788 - val_accuracy: 0.8550\n",
      "Epoch 58/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8391 - val_loss: 0.3585 - val_accuracy: 0.8501\n",
      "Epoch 59/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8470 - val_loss: 0.3607 - val_accuracy: 0.8554\n",
      "Epoch 60/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8446 - val_loss: 0.3677 - val_accuracy: 0.8550\n",
      "Epoch 61/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3566 - accuracy: 0.8419 - val_loss: 0.3702 - val_accuracy: 0.8546\n",
      "Epoch 62/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8446 - val_loss: 0.3680 - val_accuracy: 0.8576\n",
      "Epoch 63/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8418 - val_loss: 0.3553 - val_accuracy: 0.8561\n",
      "Epoch 64/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8449 - val_loss: 0.3612 - val_accuracy: 0.8565\n",
      "Epoch 65/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8406 - val_loss: 0.3702 - val_accuracy: 0.8573\n",
      "Epoch 66/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8401 - val_loss: 0.3664 - val_accuracy: 0.8565\n",
      "Epoch 67/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8447 - val_loss: 0.3931 - val_accuracy: 0.8391\n",
      "Epoch 68/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8414 - val_loss: 0.3615 - val_accuracy: 0.8576\n",
      "Epoch 69/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8416 - val_loss: 0.3614 - val_accuracy: 0.8516\n",
      "Epoch 70/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8440 - val_loss: 0.3570 - val_accuracy: 0.8591\n",
      "Epoch 71/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8451 - val_loss: 0.3565 - val_accuracy: 0.8550\n",
      "Epoch 72/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8425 - val_loss: 0.3551 - val_accuracy: 0.8584\n",
      "Epoch 73/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8433 - val_loss: 0.3584 - val_accuracy: 0.8523\n",
      "Epoch 74/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8397 - val_loss: 0.3652 - val_accuracy: 0.8569\n",
      "Epoch 75/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8451 - val_loss: 0.3682 - val_accuracy: 0.8557\n",
      "Epoch 76/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8438 - val_loss: 0.3555 - val_accuracy: 0.8599\n",
      "Epoch 77/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8436 - val_loss: 0.3618 - val_accuracy: 0.8542\n",
      "Epoch 78/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8412 - val_loss: 0.3618 - val_accuracy: 0.8542\n",
      "Epoch 79/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8451 - val_loss: 0.3867 - val_accuracy: 0.8538\n",
      "Epoch 80/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3512 - accuracy: 0.8431 - val_loss: 0.3721 - val_accuracy: 0.8459\n",
      "Epoch 81/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3519 - accuracy: 0.8405 - val_loss: 0.3731 - val_accuracy: 0.8557\n",
      "Epoch 82/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8446 - val_loss: 0.3634 - val_accuracy: 0.8573\n",
      "Epoch 83/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8421 - val_loss: 0.3819 - val_accuracy: 0.8569\n",
      "Epoch 84/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8453 - val_loss: 0.3738 - val_accuracy: 0.8410\n",
      "Epoch 85/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8433 - val_loss: 0.3761 - val_accuracy: 0.8550\n",
      "Epoch 86/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8388 - val_loss: 0.3623 - val_accuracy: 0.8523\n",
      "Epoch 87/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8367 - val_loss: 0.3626 - val_accuracy: 0.8561\n",
      "Epoch 88/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8461 - val_loss: 0.3607 - val_accuracy: 0.8561\n",
      "Epoch 89/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8474 - val_loss: 0.3607 - val_accuracy: 0.8550\n",
      "Epoch 90/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8412 - val_loss: 0.3651 - val_accuracy: 0.8535\n",
      "Epoch 91/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8416 - val_loss: 0.3650 - val_accuracy: 0.8501\n",
      "Epoch 92/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8472 - val_loss: 0.3708 - val_accuracy: 0.8512\n",
      "Epoch 93/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3516 - accuracy: 0.8408 - val_loss: 0.3781 - val_accuracy: 0.8573\n",
      "Epoch 94/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8470 - val_loss: 0.3648 - val_accuracy: 0.8599\n",
      "Epoch 95/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8429 - val_loss: 0.3620 - val_accuracy: 0.8523\n",
      "Epoch 96/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8502 - val_loss: 0.3642 - val_accuracy: 0.8580\n",
      "Epoch 97/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8503 - val_loss: 0.3628 - val_accuracy: 0.8398\n",
      "Epoch 98/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8477 - val_loss: 0.3635 - val_accuracy: 0.8584\n",
      "Epoch 99/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8418 - val_loss: 0.3602 - val_accuracy: 0.8603\n",
      "Epoch 100/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8434 - val_loss: 0.3608 - val_accuracy: 0.8531\n",
      "Epoch 101/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8485 - val_loss: 0.3628 - val_accuracy: 0.8580\n",
      "Epoch 102/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8475 - val_loss: 0.3583 - val_accuracy: 0.8588\n",
      "Epoch 103/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8459 - val_loss: 0.3754 - val_accuracy: 0.8546\n",
      "Epoch 104/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8449 - val_loss: 0.3799 - val_accuracy: 0.8448\n",
      "Epoch 105/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8425 - val_loss: 0.3564 - val_accuracy: 0.8504\n",
      "Epoch 106/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3512 - accuracy: 0.8444 - val_loss: 0.3587 - val_accuracy: 0.8489\n",
      "Epoch 107/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8492 - val_loss: 0.3563 - val_accuracy: 0.8508\n",
      "Epoch 108/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8511 - val_loss: 0.3598 - val_accuracy: 0.8569\n",
      "Epoch 109/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8483 - val_loss: 0.3580 - val_accuracy: 0.8538\n",
      "Epoch 110/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8505 - val_loss: 0.3626 - val_accuracy: 0.8554\n",
      "Epoch 111/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8405 - val_loss: 0.3646 - val_accuracy: 0.8413\n",
      "Epoch 112/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8447 - val_loss: 0.3583 - val_accuracy: 0.8569\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8369 - val_loss: 0.3708 - val_accuracy: 0.8542\n",
      "Epoch 114/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8414 - val_loss: 0.3684 - val_accuracy: 0.8569\n",
      "Epoch 115/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8481 - val_loss: 0.3618 - val_accuracy: 0.8584\n",
      "Epoch 116/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8442 - val_loss: 0.3580 - val_accuracy: 0.8557\n",
      "Epoch 117/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8433 - val_loss: 0.3611 - val_accuracy: 0.8527\n",
      "Epoch 118/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8408 - val_loss: 0.3596 - val_accuracy: 0.8573\n",
      "Epoch 119/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8431 - val_loss: 0.3625 - val_accuracy: 0.8561\n",
      "Epoch 120/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8388 - val_loss: 0.3570 - val_accuracy: 0.8565\n",
      "Epoch 121/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8470 - val_loss: 0.3662 - val_accuracy: 0.8554\n",
      "Epoch 122/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8425 - val_loss: 0.3612 - val_accuracy: 0.8610\n",
      "Epoch 123/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8457 - val_loss: 0.3665 - val_accuracy: 0.8573\n",
      "Epoch 124/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8507 - val_loss: 0.3516 - val_accuracy: 0.8550\n",
      "Epoch 125/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8414 - val_loss: 0.3530 - val_accuracy: 0.8448\n",
      "Epoch 126/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8470 - val_loss: 0.3841 - val_accuracy: 0.8501\n",
      "Epoch 127/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.8427 - val_loss: 0.3545 - val_accuracy: 0.8565\n",
      "Epoch 128/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8406 - val_loss: 0.3614 - val_accuracy: 0.8459\n",
      "Epoch 129/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8419 - val_loss: 0.3697 - val_accuracy: 0.8565\n",
      "Epoch 130/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8468 - val_loss: 0.3858 - val_accuracy: 0.8565\n",
      "Epoch 131/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8474 - val_loss: 0.3717 - val_accuracy: 0.8425\n",
      "Epoch 132/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3386 - accuracy: 0.8492 - val_loss: 0.3818 - val_accuracy: 0.8516\n",
      "Epoch 133/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8474 - val_loss: 0.3679 - val_accuracy: 0.8531\n",
      "Epoch 134/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8479 - val_loss: 0.3639 - val_accuracy: 0.8550\n",
      "Epoch 135/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8425 - val_loss: 0.3754 - val_accuracy: 0.8512\n",
      "Epoch 136/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8474 - val_loss: 0.3677 - val_accuracy: 0.8535\n",
      "Epoch 137/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8423 - val_loss: 0.3659 - val_accuracy: 0.8535\n",
      "Epoch 138/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8362 - val_loss: 0.3651 - val_accuracy: 0.8538\n",
      "Epoch 139/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8397 - val_loss: 0.3602 - val_accuracy: 0.8565\n",
      "Epoch 140/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8434 - val_loss: 0.3584 - val_accuracy: 0.8569\n",
      "Epoch 141/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8433 - val_loss: 0.3587 - val_accuracy: 0.8546\n",
      "Epoch 142/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8520 - val_loss: 0.3634 - val_accuracy: 0.8591\n",
      "Epoch 143/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8436 - val_loss: 0.3710 - val_accuracy: 0.8591\n",
      "Epoch 144/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8405 - val_loss: 0.3723 - val_accuracy: 0.8501\n",
      "Epoch 145/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8425 - val_loss: 0.3655 - val_accuracy: 0.8497\n",
      "Epoch 146/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8431 - val_loss: 0.3723 - val_accuracy: 0.8603\n",
      "Epoch 147/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8416 - val_loss: 0.3777 - val_accuracy: 0.8383\n",
      "Epoch 148/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8446 - val_loss: 0.3620 - val_accuracy: 0.8557\n",
      "Epoch 149/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8425 - val_loss: 0.3637 - val_accuracy: 0.8550\n",
      "Epoch 150/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8442 - val_loss: 0.3707 - val_accuracy: 0.8516\n",
      "Epoch 151/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8485 - val_loss: 0.3645 - val_accuracy: 0.8580\n",
      "Epoch 152/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8453 - val_loss: 0.3735 - val_accuracy: 0.8353\n",
      "Epoch 153/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8419 - val_loss: 0.3731 - val_accuracy: 0.8576\n",
      "Epoch 154/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8440 - val_loss: 0.3687 - val_accuracy: 0.8569\n",
      "Epoch 155/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8408 - val_loss: 0.3591 - val_accuracy: 0.8576\n",
      "Epoch 156/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8412 - val_loss: 0.3595 - val_accuracy: 0.8576\n",
      "Epoch 157/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8446 - val_loss: 0.3635 - val_accuracy: 0.8561\n",
      "Epoch 158/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8423 - val_loss: 0.3732 - val_accuracy: 0.8546\n",
      "Epoch 159/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8416 - val_loss: 0.3671 - val_accuracy: 0.8550\n",
      "Epoch 160/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8436 - val_loss: 0.3777 - val_accuracy: 0.8538\n",
      "Epoch 161/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8459 - val_loss: 0.3638 - val_accuracy: 0.8497\n",
      "Epoch 162/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8457 - val_loss: 0.3674 - val_accuracy: 0.8542\n",
      "Epoch 163/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8429 - val_loss: 0.3815 - val_accuracy: 0.8531\n",
      "Epoch 164/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8442 - val_loss: 0.3737 - val_accuracy: 0.8546\n",
      "Epoch 165/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8431 - val_loss: 0.3840 - val_accuracy: 0.8561\n",
      "Epoch 166/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8442 - val_loss: 0.3781 - val_accuracy: 0.8535\n",
      "Epoch 167/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8431 - val_loss: 0.3797 - val_accuracy: 0.8569\n",
      "Epoch 168/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8405 - val_loss: 0.3745 - val_accuracy: 0.8542\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8419 - val_loss: 0.3936 - val_accuracy: 0.8535\n",
      "Epoch 170/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8378 - val_loss: 0.3812 - val_accuracy: 0.8542\n",
      "Epoch 171/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8453 - val_loss: 0.3924 - val_accuracy: 0.8387\n",
      "Epoch 172/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8399 - val_loss: 0.3787 - val_accuracy: 0.8550\n",
      "Epoch 173/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8444 - val_loss: 0.3712 - val_accuracy: 0.8402\n",
      "Epoch 174/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8449 - val_loss: 0.3780 - val_accuracy: 0.8372\n",
      "Epoch 175/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8406 - val_loss: 0.3809 - val_accuracy: 0.8531\n",
      "Epoch 176/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8431 - val_loss: 0.3974 - val_accuracy: 0.8455\n",
      "Epoch 177/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3411 - accuracy: 0.8457 - val_loss: 0.3877 - val_accuracy: 0.8531\n",
      "Epoch 178/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8427 - val_loss: 0.4069 - val_accuracy: 0.8512\n",
      "Epoch 179/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8459 - val_loss: 0.3638 - val_accuracy: 0.8497\n",
      "Epoch 180/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8427 - val_loss: 0.3668 - val_accuracy: 0.8519\n",
      "Epoch 181/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8433 - val_loss: 0.3796 - val_accuracy: 0.8550\n",
      "Epoch 182/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8406 - val_loss: 0.3747 - val_accuracy: 0.8542\n",
      "Epoch 183/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8438 - val_loss: 0.3855 - val_accuracy: 0.8519\n",
      "Epoch 184/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8434 - val_loss: 0.3777 - val_accuracy: 0.8474\n",
      "Epoch 185/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8431 - val_loss: 0.3684 - val_accuracy: 0.8546\n",
      "Epoch 186/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8485 - val_loss: 0.3731 - val_accuracy: 0.8550\n",
      "Epoch 187/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8444 - val_loss: 0.3890 - val_accuracy: 0.8550\n",
      "Epoch 188/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8490 - val_loss: 0.3906 - val_accuracy: 0.8535\n",
      "Epoch 189/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8475 - val_loss: 0.4093 - val_accuracy: 0.8550\n",
      "Epoch 190/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8395 - val_loss: 0.3775 - val_accuracy: 0.8542\n",
      "Epoch 191/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8418 - val_loss: 0.3912 - val_accuracy: 0.8561\n",
      "Epoch 192/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8418 - val_loss: 0.3874 - val_accuracy: 0.8501\n",
      "Epoch 193/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8395 - val_loss: 0.3797 - val_accuracy: 0.8474\n",
      "Epoch 194/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8375 - val_loss: 0.3837 - val_accuracy: 0.8573\n",
      "Epoch 195/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8395 - val_loss: 0.3985 - val_accuracy: 0.8546\n",
      "Epoch 196/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8449 - val_loss: 0.3786 - val_accuracy: 0.8504\n",
      "Epoch 197/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8462 - val_loss: 0.3745 - val_accuracy: 0.8455\n",
      "Epoch 198/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8388 - val_loss: 0.3757 - val_accuracy: 0.8463\n",
      "Epoch 199/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8421 - val_loss: 0.3706 - val_accuracy: 0.8565\n",
      "Epoch 200/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8412 - val_loss: 0.3844 - val_accuracy: 0.8565\n",
      "Epoch 201/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8406 - val_loss: 0.3756 - val_accuracy: 0.8554\n",
      "Epoch 202/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8373 - val_loss: 0.3846 - val_accuracy: 0.8531\n",
      "Epoch 203/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8403 - val_loss: 0.3763 - val_accuracy: 0.8561\n",
      "Epoch 204/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8399 - val_loss: 0.3858 - val_accuracy: 0.8519\n",
      "Epoch 205/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8461 - val_loss: 0.3918 - val_accuracy: 0.8444\n",
      "Epoch 206/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3521 - accuracy: 0.8434 - val_loss: 0.3922 - val_accuracy: 0.8455\n",
      "Epoch 207/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8459 - val_loss: 0.3604 - val_accuracy: 0.8588\n",
      "Epoch 208/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8436 - val_loss: 0.3682 - val_accuracy: 0.8550\n",
      "Epoch 209/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8429 - val_loss: 0.3725 - val_accuracy: 0.8550\n",
      "Epoch 210/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8446 - val_loss: 0.3757 - val_accuracy: 0.8504\n",
      "Epoch 211/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8397 - val_loss: 0.3781 - val_accuracy: 0.8527\n",
      "Epoch 212/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8479 - val_loss: 0.3857 - val_accuracy: 0.8603\n",
      "Epoch 213/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8431 - val_loss: 0.3720 - val_accuracy: 0.8535\n",
      "Epoch 214/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8479 - val_loss: 0.3723 - val_accuracy: 0.8538\n",
      "Epoch 215/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8468 - val_loss: 0.3827 - val_accuracy: 0.8440\n",
      "Epoch 216/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8377 - val_loss: 0.3720 - val_accuracy: 0.8516\n",
      "Epoch 217/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3411 - accuracy: 0.8403 - val_loss: 0.4186 - val_accuracy: 0.8527\n",
      "Epoch 218/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8436 - val_loss: 0.3746 - val_accuracy: 0.8550\n",
      "Epoch 219/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8481 - val_loss: 0.3718 - val_accuracy: 0.8580\n",
      "Epoch 220/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8459 - val_loss: 0.3884 - val_accuracy: 0.8554\n",
      "Epoch 221/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8436 - val_loss: 0.3928 - val_accuracy: 0.8508\n",
      "Epoch 222/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8390 - val_loss: 0.3831 - val_accuracy: 0.8542\n",
      "Epoch 223/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8419 - val_loss: 0.3835 - val_accuracy: 0.8584\n",
      "Epoch 224/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8438 - val_loss: 0.3919 - val_accuracy: 0.8580\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8403 - val_loss: 0.4346 - val_accuracy: 0.8523\n",
      "Epoch 226/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8408 - val_loss: 0.3890 - val_accuracy: 0.8557\n",
      "Epoch 227/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8470 - val_loss: 0.4280 - val_accuracy: 0.8550\n",
      "Epoch 228/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8496 - val_loss: 0.3938 - val_accuracy: 0.8519\n",
      "Epoch 229/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8457 - val_loss: 0.4069 - val_accuracy: 0.8542\n",
      "Epoch 230/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8459 - val_loss: 0.4158 - val_accuracy: 0.8512\n",
      "Epoch 231/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8408 - val_loss: 0.4100 - val_accuracy: 0.8580\n",
      "Epoch 232/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8440 - val_loss: 0.4216 - val_accuracy: 0.8523\n",
      "Epoch 233/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8429 - val_loss: 0.4094 - val_accuracy: 0.8569\n",
      "Epoch 234/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8410 - val_loss: 0.3741 - val_accuracy: 0.8527\n",
      "Epoch 235/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8406 - val_loss: 0.3770 - val_accuracy: 0.8546\n",
      "Epoch 236/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8406 - val_loss: 0.3880 - val_accuracy: 0.8482\n",
      "Epoch 237/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8447 - val_loss: 0.3945 - val_accuracy: 0.8531\n",
      "Epoch 238/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8444 - val_loss: 0.3844 - val_accuracy: 0.8379\n",
      "Epoch 239/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8388 - val_loss: 0.3748 - val_accuracy: 0.8561\n",
      "Epoch 240/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8481 - val_loss: 0.3667 - val_accuracy: 0.8535\n",
      "Epoch 241/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8444 - val_loss: 0.3928 - val_accuracy: 0.8523\n",
      "Epoch 242/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8496 - val_loss: 0.3992 - val_accuracy: 0.8546\n",
      "Epoch 243/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8429 - val_loss: 0.3862 - val_accuracy: 0.8512\n",
      "Epoch 244/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8410 - val_loss: 0.3644 - val_accuracy: 0.8542\n",
      "Epoch 245/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8498 - val_loss: 0.3646 - val_accuracy: 0.8512\n",
      "Epoch 246/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8408 - val_loss: 0.3705 - val_accuracy: 0.8489\n",
      "Epoch 247/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8453 - val_loss: 0.3665 - val_accuracy: 0.8557\n",
      "Epoch 248/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8403 - val_loss: 0.3876 - val_accuracy: 0.8546\n",
      "Epoch 249/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8462 - val_loss: 0.3749 - val_accuracy: 0.8482\n",
      "Epoch 250/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8410 - val_loss: 0.3886 - val_accuracy: 0.8459\n",
      "Epoch 251/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8421 - val_loss: 0.4155 - val_accuracy: 0.8546\n",
      "Epoch 252/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8438 - val_loss: 0.4035 - val_accuracy: 0.8603\n",
      "Epoch 253/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3385 - accuracy: 0.8475 - val_loss: 0.4275 - val_accuracy: 0.8395\n",
      "Epoch 254/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8440 - val_loss: 0.4547 - val_accuracy: 0.8546\n",
      "Epoch 255/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8518 - val_loss: 0.3776 - val_accuracy: 0.8588\n",
      "Epoch 256/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8397 - val_loss: 0.4050 - val_accuracy: 0.8485\n",
      "Epoch 257/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8459 - val_loss: 0.4013 - val_accuracy: 0.8557\n",
      "Epoch 258/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3516 - accuracy: 0.8423 - val_loss: 0.3888 - val_accuracy: 0.8550\n",
      "Epoch 259/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8459 - val_loss: 0.4058 - val_accuracy: 0.8296\n",
      "Epoch 260/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3383 - accuracy: 0.8431 - val_loss: 0.3814 - val_accuracy: 0.8554\n",
      "Epoch 261/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8481 - val_loss: 0.4085 - val_accuracy: 0.8550\n",
      "Epoch 262/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8485 - val_loss: 0.3986 - val_accuracy: 0.8573\n",
      "Epoch 263/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8451 - val_loss: 0.3841 - val_accuracy: 0.8591\n",
      "Epoch 264/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8438 - val_loss: 0.3886 - val_accuracy: 0.8372\n",
      "Epoch 265/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8446 - val_loss: 0.3853 - val_accuracy: 0.8591\n",
      "Epoch 266/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8419 - val_loss: 0.3948 - val_accuracy: 0.8588\n",
      "Epoch 267/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8393 - val_loss: 0.4129 - val_accuracy: 0.8436\n",
      "Epoch 268/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8397 - val_loss: 0.4068 - val_accuracy: 0.8584\n",
      "Epoch 269/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8485 - val_loss: 0.4241 - val_accuracy: 0.8512\n",
      "Epoch 270/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8418 - val_loss: 0.4252 - val_accuracy: 0.8561\n",
      "Epoch 271/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8365 - val_loss: 0.3697 - val_accuracy: 0.8436\n",
      "Epoch 272/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8412 - val_loss: 0.3803 - val_accuracy: 0.8546\n",
      "Epoch 273/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8436 - val_loss: 0.3965 - val_accuracy: 0.8554\n",
      "Epoch 274/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8438 - val_loss: 0.3993 - val_accuracy: 0.8588\n",
      "Epoch 275/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8442 - val_loss: 0.3869 - val_accuracy: 0.8569\n",
      "Epoch 276/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8433 - val_loss: 0.3918 - val_accuracy: 0.8584\n",
      "Epoch 277/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8421 - val_loss: 0.4091 - val_accuracy: 0.8580\n",
      "Epoch 278/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8464 - val_loss: 0.3861 - val_accuracy: 0.8573\n",
      "Epoch 279/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8438 - val_loss: 0.3845 - val_accuracy: 0.8546\n",
      "Epoch 280/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8433 - val_loss: 0.3894 - val_accuracy: 0.8550\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8397 - val_loss: 0.4800 - val_accuracy: 0.8557\n",
      "Epoch 282/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8429 - val_loss: 0.3863 - val_accuracy: 0.8546\n",
      "Epoch 283/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8423 - val_loss: 0.3997 - val_accuracy: 0.8497\n",
      "Epoch 284/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8410 - val_loss: 0.4086 - val_accuracy: 0.8531\n",
      "Epoch 285/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8438 - val_loss: 0.3963 - val_accuracy: 0.8508\n",
      "Epoch 286/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8434 - val_loss: 0.4303 - val_accuracy: 0.8455\n",
      "Epoch 287/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8444 - val_loss: 0.3873 - val_accuracy: 0.8489\n",
      "Epoch 288/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8451 - val_loss: 0.4118 - val_accuracy: 0.8542\n",
      "Epoch 289/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8481 - val_loss: 0.3660 - val_accuracy: 0.8565\n",
      "Epoch 290/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8459 - val_loss: 0.3698 - val_accuracy: 0.8478\n",
      "Epoch 291/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8423 - val_loss: 0.3670 - val_accuracy: 0.8591\n",
      "Epoch 292/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8408 - val_loss: 0.3707 - val_accuracy: 0.8591\n",
      "Epoch 293/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8451 - val_loss: 0.3813 - val_accuracy: 0.8512\n",
      "Epoch 294/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8462 - val_loss: 0.3838 - val_accuracy: 0.8554\n",
      "Epoch 295/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8474 - val_loss: 0.3855 - val_accuracy: 0.8501\n",
      "Epoch 296/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8466 - val_loss: 0.3854 - val_accuracy: 0.8451\n",
      "Epoch 297/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8474 - val_loss: 0.3768 - val_accuracy: 0.8531\n",
      "Epoch 298/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8434 - val_loss: 0.3802 - val_accuracy: 0.8591\n",
      "Epoch 299/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8419 - val_loss: 0.3750 - val_accuracy: 0.8519\n",
      "Epoch 300/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8442 - val_loss: 0.3825 - val_accuracy: 0.8599\n",
      "Epoch 301/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8405 - val_loss: 0.4002 - val_accuracy: 0.8637\n",
      "Epoch 302/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8442 - val_loss: 0.3862 - val_accuracy: 0.8614\n",
      "Epoch 303/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8431 - val_loss: 0.3926 - val_accuracy: 0.8591\n",
      "Epoch 304/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8414 - val_loss: 0.3995 - val_accuracy: 0.8569\n",
      "Epoch 305/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8440 - val_loss: 0.4163 - val_accuracy: 0.8595\n",
      "Epoch 306/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8479 - val_loss: 0.3803 - val_accuracy: 0.8550\n",
      "Epoch 307/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8427 - val_loss: 0.4154 - val_accuracy: 0.8546\n",
      "Epoch 308/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8352 - val_loss: 0.3880 - val_accuracy: 0.8588\n",
      "Epoch 309/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8457 - val_loss: 0.3829 - val_accuracy: 0.8561\n",
      "Epoch 310/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8462 - val_loss: 0.3885 - val_accuracy: 0.8554\n",
      "Epoch 311/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8436 - val_loss: 0.3993 - val_accuracy: 0.8554\n",
      "Epoch 312/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8440 - val_loss: 0.3845 - val_accuracy: 0.8561\n",
      "Epoch 313/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8444 - val_loss: 0.3866 - val_accuracy: 0.8444\n",
      "Epoch 314/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8401 - val_loss: 0.3884 - val_accuracy: 0.8610\n",
      "Epoch 315/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8433 - val_loss: 0.3859 - val_accuracy: 0.8478\n",
      "Epoch 316/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8457 - val_loss: 0.3811 - val_accuracy: 0.8580\n",
      "Epoch 317/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8483 - val_loss: 0.3805 - val_accuracy: 0.8527\n",
      "Epoch 318/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8464 - val_loss: 0.4208 - val_accuracy: 0.8569\n",
      "Epoch 319/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8434 - val_loss: 0.3803 - val_accuracy: 0.8573\n",
      "Epoch 320/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8421 - val_loss: 0.3985 - val_accuracy: 0.8584\n",
      "Epoch 321/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8393 - val_loss: 0.4015 - val_accuracy: 0.8576\n",
      "Epoch 322/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8401 - val_loss: 0.3901 - val_accuracy: 0.8591\n",
      "Epoch 323/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8418 - val_loss: 0.3751 - val_accuracy: 0.8580\n",
      "Epoch 324/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8399 - val_loss: 0.4095 - val_accuracy: 0.8565\n",
      "Epoch 325/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8425 - val_loss: 0.4076 - val_accuracy: 0.8542\n",
      "Epoch 326/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8414 - val_loss: 0.4131 - val_accuracy: 0.8478\n",
      "Epoch 327/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8408 - val_loss: 0.3941 - val_accuracy: 0.8557\n",
      "Epoch 328/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8446 - val_loss: 0.4082 - val_accuracy: 0.8557\n",
      "Epoch 329/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8416 - val_loss: 0.3863 - val_accuracy: 0.8580\n",
      "Epoch 330/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8408 - val_loss: 0.3798 - val_accuracy: 0.8591\n",
      "Epoch 331/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8434 - val_loss: 0.4014 - val_accuracy: 0.8554\n",
      "Epoch 332/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8436 - val_loss: 0.4026 - val_accuracy: 0.8523\n",
      "Epoch 333/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8436 - val_loss: 0.4162 - val_accuracy: 0.8474\n",
      "Epoch 334/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3541 - accuracy: 0.8393 - val_loss: 0.4754 - val_accuracy: 0.8485\n",
      "Epoch 335/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8468 - val_loss: 0.4047 - val_accuracy: 0.8584\n",
      "Epoch 336/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8518 - val_loss: 0.3978 - val_accuracy: 0.8542\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8423 - val_loss: 0.3907 - val_accuracy: 0.8569\n",
      "Epoch 338/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8444 - val_loss: 0.3915 - val_accuracy: 0.8444\n",
      "Epoch 339/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8457 - val_loss: 0.3888 - val_accuracy: 0.8595\n",
      "Epoch 340/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8449 - val_loss: 0.3959 - val_accuracy: 0.8584\n",
      "Epoch 341/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8470 - val_loss: 0.3807 - val_accuracy: 0.8580\n",
      "Epoch 342/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8406 - val_loss: 0.4012 - val_accuracy: 0.8448\n",
      "Epoch 343/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8475 - val_loss: 0.3796 - val_accuracy: 0.8436\n",
      "Epoch 344/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8498 - val_loss: 0.3785 - val_accuracy: 0.8584\n",
      "Epoch 345/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8442 - val_loss: 0.3828 - val_accuracy: 0.8448\n",
      "Epoch 346/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8433 - val_loss: 0.3981 - val_accuracy: 0.8429\n",
      "Epoch 347/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8412 - val_loss: 0.3981 - val_accuracy: 0.8550\n",
      "Epoch 348/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8472 - val_loss: 0.3994 - val_accuracy: 0.8557\n",
      "Epoch 349/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8462 - val_loss: 0.4282 - val_accuracy: 0.8542\n",
      "Epoch 350/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8481 - val_loss: 0.3889 - val_accuracy: 0.8561\n",
      "Epoch 351/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8414 - val_loss: 0.4190 - val_accuracy: 0.8538\n",
      "Epoch 352/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8438 - val_loss: 0.4026 - val_accuracy: 0.8576\n",
      "Epoch 353/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8414 - val_loss: 0.4022 - val_accuracy: 0.8576\n",
      "Epoch 354/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8468 - val_loss: 0.4059 - val_accuracy: 0.8451\n",
      "Epoch 355/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8464 - val_loss: 0.3965 - val_accuracy: 0.8561\n",
      "Epoch 356/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8457 - val_loss: 0.3943 - val_accuracy: 0.8417\n",
      "Epoch 357/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8447 - val_loss: 0.3892 - val_accuracy: 0.8614\n",
      "Epoch 358/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8453 - val_loss: 0.4197 - val_accuracy: 0.8538\n",
      "Epoch 359/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8397 - val_loss: 0.4116 - val_accuracy: 0.8455\n",
      "Epoch 360/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8449 - val_loss: 0.4157 - val_accuracy: 0.8538\n",
      "Epoch 361/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8427 - val_loss: 0.4185 - val_accuracy: 0.8546\n",
      "Epoch 362/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8438 - val_loss: 0.4092 - val_accuracy: 0.8584\n",
      "Epoch 363/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8427 - val_loss: 0.3928 - val_accuracy: 0.8546\n",
      "Epoch 364/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8412 - val_loss: 0.4359 - val_accuracy: 0.8584\n",
      "Epoch 365/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8380 - val_loss: 0.4188 - val_accuracy: 0.8569\n",
      "Epoch 366/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8447 - val_loss: 0.3916 - val_accuracy: 0.8531\n",
      "Epoch 367/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8438 - val_loss: 0.3861 - val_accuracy: 0.8516\n",
      "Epoch 368/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8390 - val_loss: 0.4167 - val_accuracy: 0.8516\n",
      "Epoch 369/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8455 - val_loss: 0.3973 - val_accuracy: 0.8516\n",
      "Epoch 370/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8414 - val_loss: 0.4033 - val_accuracy: 0.8523\n",
      "Epoch 371/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8472 - val_loss: 0.4207 - val_accuracy: 0.8516\n",
      "Epoch 372/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8423 - val_loss: 0.4152 - val_accuracy: 0.8569\n",
      "Epoch 373/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8356 - val_loss: 0.4012 - val_accuracy: 0.8557\n",
      "Epoch 374/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8440 - val_loss: 0.3997 - val_accuracy: 0.8493\n",
      "Epoch 375/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8461 - val_loss: 0.4434 - val_accuracy: 0.8546\n",
      "Epoch 376/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8451 - val_loss: 0.4090 - val_accuracy: 0.8504\n",
      "Epoch 377/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8462 - val_loss: 0.3980 - val_accuracy: 0.8546\n",
      "Epoch 378/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8498 - val_loss: 0.3980 - val_accuracy: 0.8546\n",
      "Epoch 379/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8496 - val_loss: 0.3825 - val_accuracy: 0.8519\n",
      "Epoch 380/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8543 - val_loss: 0.4072 - val_accuracy: 0.8550\n",
      "Epoch 381/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8457 - val_loss: 0.4029 - val_accuracy: 0.8565\n",
      "Epoch 382/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8408 - val_loss: 0.4488 - val_accuracy: 0.8531\n",
      "Epoch 383/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8434 - val_loss: 0.4496 - val_accuracy: 0.8557\n",
      "Epoch 384/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8425 - val_loss: 0.3917 - val_accuracy: 0.8410\n",
      "Epoch 385/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8399 - val_loss: 0.3847 - val_accuracy: 0.8565\n",
      "Epoch 386/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8453 - val_loss: 0.4121 - val_accuracy: 0.8425\n",
      "Epoch 387/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8436 - val_loss: 0.4197 - val_accuracy: 0.8527\n",
      "Epoch 388/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8414 - val_loss: 0.3963 - val_accuracy: 0.8542\n",
      "Epoch 389/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8447 - val_loss: 0.4495 - val_accuracy: 0.8569\n",
      "Epoch 390/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8436 - val_loss: 0.3716 - val_accuracy: 0.8550\n",
      "Epoch 391/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8418 - val_loss: 0.4048 - val_accuracy: 0.8557\n",
      "Epoch 392/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8447 - val_loss: 0.3991 - val_accuracy: 0.8531\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8496 - val_loss: 0.3935 - val_accuracy: 0.8561\n",
      "Epoch 394/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8442 - val_loss: 0.3788 - val_accuracy: 0.8561\n",
      "Epoch 395/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8427 - val_loss: 0.4004 - val_accuracy: 0.8573\n",
      "Epoch 396/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8434 - val_loss: 0.4495 - val_accuracy: 0.8580\n",
      "Epoch 397/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8466 - val_loss: 0.3787 - val_accuracy: 0.8569\n",
      "Epoch 398/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8461 - val_loss: 0.4022 - val_accuracy: 0.8580\n",
      "Epoch 399/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3388 - accuracy: 0.8472 - val_loss: 0.3944 - val_accuracy: 0.8535\n",
      "Epoch 400/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8444 - val_loss: 0.3951 - val_accuracy: 0.8535\n",
      "Epoch 401/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8410 - val_loss: 0.3986 - val_accuracy: 0.8523\n",
      "Epoch 402/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8373 - val_loss: 0.4616 - val_accuracy: 0.8501\n",
      "Epoch 403/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8386 - val_loss: 0.3964 - val_accuracy: 0.8512\n",
      "Epoch 404/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8412 - val_loss: 0.4108 - val_accuracy: 0.8516\n",
      "Epoch 405/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8453 - val_loss: 0.3990 - val_accuracy: 0.8417\n",
      "Epoch 406/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8446 - val_loss: 0.4692 - val_accuracy: 0.8402\n",
      "Epoch 407/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8455 - val_loss: 0.4125 - val_accuracy: 0.8489\n",
      "Epoch 408/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8388 - val_loss: 0.3877 - val_accuracy: 0.8470\n",
      "Epoch 409/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8446 - val_loss: 0.4280 - val_accuracy: 0.8569\n",
      "Epoch 410/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8386 - val_loss: 0.4586 - val_accuracy: 0.8368\n",
      "Epoch 411/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8470 - val_loss: 0.4307 - val_accuracy: 0.8542\n",
      "Epoch 412/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8425 - val_loss: 0.4175 - val_accuracy: 0.8398\n",
      "Epoch 413/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8414 - val_loss: 0.4564 - val_accuracy: 0.8406\n",
      "Epoch 414/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8475 - val_loss: 0.4502 - val_accuracy: 0.8550\n",
      "Epoch 415/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8451 - val_loss: 0.4550 - val_accuracy: 0.8448\n",
      "Epoch 416/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8449 - val_loss: 0.4231 - val_accuracy: 0.8523\n",
      "Epoch 417/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8466 - val_loss: 0.4469 - val_accuracy: 0.8508\n",
      "Epoch 418/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8423 - val_loss: 0.4340 - val_accuracy: 0.8444\n",
      "Epoch 419/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8410 - val_loss: 0.3893 - val_accuracy: 0.8455\n",
      "Epoch 420/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8464 - val_loss: 0.3955 - val_accuracy: 0.8440\n",
      "Epoch 421/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8416 - val_loss: 0.4030 - val_accuracy: 0.8421\n",
      "Epoch 422/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8453 - val_loss: 0.4176 - val_accuracy: 0.8554\n",
      "Epoch 423/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8391 - val_loss: 0.4369 - val_accuracy: 0.8417\n",
      "Epoch 424/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8423 - val_loss: 0.4343 - val_accuracy: 0.8501\n",
      "Epoch 425/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8455 - val_loss: 0.4003 - val_accuracy: 0.8508\n",
      "Epoch 426/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8408 - val_loss: 0.4227 - val_accuracy: 0.8508\n",
      "Epoch 427/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8418 - val_loss: 0.3947 - val_accuracy: 0.8550\n",
      "Epoch 428/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8429 - val_loss: 0.3990 - val_accuracy: 0.8512\n",
      "Epoch 429/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8457 - val_loss: 0.3890 - val_accuracy: 0.8512\n",
      "Epoch 430/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8442 - val_loss: 0.4205 - val_accuracy: 0.8569\n",
      "Epoch 431/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8487 - val_loss: 0.4198 - val_accuracy: 0.8470\n",
      "Epoch 432/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8434 - val_loss: 0.4302 - val_accuracy: 0.8557\n",
      "Epoch 433/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8503 - val_loss: 0.4053 - val_accuracy: 0.8584\n",
      "Epoch 434/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8472 - val_loss: 0.4472 - val_accuracy: 0.8569\n",
      "Epoch 435/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8509 - val_loss: 0.4375 - val_accuracy: 0.8546\n",
      "Epoch 436/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8438 - val_loss: 0.4669 - val_accuracy: 0.8527\n",
      "Epoch 437/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8479 - val_loss: 0.4150 - val_accuracy: 0.8614\n",
      "Epoch 438/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8470 - val_loss: 0.4076 - val_accuracy: 0.8561\n",
      "Epoch 439/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8395 - val_loss: 0.4031 - val_accuracy: 0.8410\n",
      "Epoch 440/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8406 - val_loss: 0.3926 - val_accuracy: 0.8561\n",
      "Epoch 441/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8397 - val_loss: 0.3947 - val_accuracy: 0.8501\n",
      "Epoch 442/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3429 - accuracy: 0.8459 - val_loss: 0.3775 - val_accuracy: 0.8580\n",
      "Epoch 443/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8451 - val_loss: 0.4095 - val_accuracy: 0.8512\n",
      "Epoch 444/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8390 - val_loss: 0.4874 - val_accuracy: 0.8561\n",
      "Epoch 445/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8434 - val_loss: 0.4237 - val_accuracy: 0.8523\n",
      "Epoch 446/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8462 - val_loss: 0.3846 - val_accuracy: 0.8527\n",
      "Epoch 447/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8481 - val_loss: 0.4027 - val_accuracy: 0.8466\n",
      "Epoch 448/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8433 - val_loss: 0.4333 - val_accuracy: 0.8576\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8447 - val_loss: 0.4734 - val_accuracy: 0.8527\n",
      "Epoch 450/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8419 - val_loss: 0.3892 - val_accuracy: 0.8573\n",
      "Epoch 451/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8431 - val_loss: 0.3806 - val_accuracy: 0.8527\n",
      "Epoch 452/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8461 - val_loss: 0.3940 - val_accuracy: 0.8383\n",
      "Epoch 453/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8421 - val_loss: 0.4018 - val_accuracy: 0.8561\n",
      "Epoch 454/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8462 - val_loss: 0.3849 - val_accuracy: 0.8569\n",
      "Epoch 455/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8472 - val_loss: 0.3820 - val_accuracy: 0.8542\n",
      "Epoch 456/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8429 - val_loss: 0.3993 - val_accuracy: 0.8459\n",
      "Epoch 457/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8412 - val_loss: 0.3901 - val_accuracy: 0.8542\n",
      "Epoch 458/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3411 - accuracy: 0.8429 - val_loss: 0.3906 - val_accuracy: 0.8531\n",
      "Epoch 459/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3370 - accuracy: 0.8500 - val_loss: 0.4083 - val_accuracy: 0.8557\n",
      "Epoch 460/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8440 - val_loss: 0.4001 - val_accuracy: 0.8523\n",
      "Epoch 461/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8436 - val_loss: 0.3858 - val_accuracy: 0.8512\n",
      "Epoch 462/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8440 - val_loss: 0.3666 - val_accuracy: 0.8546\n",
      "Epoch 463/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8421 - val_loss: 0.3839 - val_accuracy: 0.8493\n",
      "Epoch 464/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8459 - val_loss: 0.3792 - val_accuracy: 0.8470\n",
      "Epoch 465/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8453 - val_loss: 0.3858 - val_accuracy: 0.8512\n",
      "Epoch 466/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8438 - val_loss: 0.4012 - val_accuracy: 0.8444\n",
      "Epoch 467/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8382 - val_loss: 0.3846 - val_accuracy: 0.8527\n",
      "Epoch 468/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8388 - val_loss: 0.4019 - val_accuracy: 0.8451\n",
      "Epoch 469/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8457 - val_loss: 0.3923 - val_accuracy: 0.8531\n",
      "Epoch 470/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8360 - val_loss: 0.4125 - val_accuracy: 0.8338\n",
      "Epoch 471/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.8345 - val_loss: 0.4066 - val_accuracy: 0.8482\n",
      "Epoch 472/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8455 - val_loss: 0.3863 - val_accuracy: 0.8535\n",
      "Epoch 473/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8468 - val_loss: 0.4008 - val_accuracy: 0.8565\n",
      "Epoch 474/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8455 - val_loss: 0.3788 - val_accuracy: 0.8565\n",
      "Epoch 475/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8436 - val_loss: 0.4011 - val_accuracy: 0.8588\n",
      "Epoch 476/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8455 - val_loss: 0.3896 - val_accuracy: 0.8576\n",
      "Epoch 477/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8401 - val_loss: 0.4052 - val_accuracy: 0.8538\n",
      "Epoch 478/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8410 - val_loss: 0.4090 - val_accuracy: 0.8550\n",
      "Epoch 479/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8453 - val_loss: 0.3744 - val_accuracy: 0.8531\n",
      "Epoch 480/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8403 - val_loss: 0.3747 - val_accuracy: 0.8531\n",
      "Epoch 481/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8434 - val_loss: 0.3911 - val_accuracy: 0.8482\n",
      "Epoch 482/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8406 - val_loss: 0.3690 - val_accuracy: 0.8569\n",
      "Epoch 483/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8405 - val_loss: 0.3690 - val_accuracy: 0.8565\n",
      "Epoch 484/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8436 - val_loss: 0.4070 - val_accuracy: 0.8554\n",
      "Epoch 485/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8423 - val_loss: 0.4056 - val_accuracy: 0.8519\n",
      "Epoch 486/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8468 - val_loss: 0.3810 - val_accuracy: 0.8413\n",
      "Epoch 487/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8418 - val_loss: 0.3786 - val_accuracy: 0.8573\n",
      "Epoch 488/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8390 - val_loss: 0.3713 - val_accuracy: 0.8573\n",
      "Epoch 489/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8431 - val_loss: 0.3838 - val_accuracy: 0.8550\n",
      "Epoch 490/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8459 - val_loss: 0.4003 - val_accuracy: 0.8591\n",
      "Epoch 491/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8468 - val_loss: 0.4153 - val_accuracy: 0.8576\n",
      "Epoch 492/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8434 - val_loss: 0.4306 - val_accuracy: 0.8554\n",
      "Epoch 493/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8498 - val_loss: 0.4142 - val_accuracy: 0.8561\n",
      "Epoch 494/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8440 - val_loss: 0.4520 - val_accuracy: 0.8565\n",
      "Epoch 495/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8533 - val_loss: 0.3968 - val_accuracy: 0.8569\n",
      "Epoch 496/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8494 - val_loss: 0.3636 - val_accuracy: 0.8576\n",
      "Epoch 497/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8436 - val_loss: 0.3700 - val_accuracy: 0.8546\n",
      "Epoch 498/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8401 - val_loss: 0.3711 - val_accuracy: 0.8482\n",
      "Epoch 499/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8427 - val_loss: 0.3765 - val_accuracy: 0.8557\n",
      "Epoch 500/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8492 - val_loss: 0.4474 - val_accuracy: 0.8584\n",
      "Epoch 501/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8466 - val_loss: 0.5426 - val_accuracy: 0.8591\n",
      "Epoch 502/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8485 - val_loss: 0.3784 - val_accuracy: 0.8569\n",
      "Epoch 503/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8455 - val_loss: 0.3759 - val_accuracy: 0.8584\n",
      "Epoch 504/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8427 - val_loss: 0.4012 - val_accuracy: 0.8576\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.8464 - val_loss: 0.4176 - val_accuracy: 0.8236\n",
      "Epoch 506/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8406 - val_loss: 0.4466 - val_accuracy: 0.8565\n",
      "Epoch 507/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8438 - val_loss: 0.3844 - val_accuracy: 0.8569\n",
      "Epoch 508/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8444 - val_loss: 0.4111 - val_accuracy: 0.8504\n",
      "Epoch 509/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8446 - val_loss: 0.4116 - val_accuracy: 0.8538\n",
      "Epoch 510/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8440 - val_loss: 0.4367 - val_accuracy: 0.8550\n",
      "Epoch 511/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8423 - val_loss: 0.4056 - val_accuracy: 0.8436\n",
      "Epoch 512/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3585 - accuracy: 0.8438 - val_loss: 0.3790 - val_accuracy: 0.8565\n",
      "Epoch 513/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8425 - val_loss: 0.4139 - val_accuracy: 0.8576\n",
      "Epoch 514/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8436 - val_loss: 0.3729 - val_accuracy: 0.8595\n",
      "Epoch 515/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8442 - val_loss: 0.4084 - val_accuracy: 0.8573\n",
      "Epoch 516/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8449 - val_loss: 0.3719 - val_accuracy: 0.8546\n",
      "Epoch 517/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8457 - val_loss: 0.3904 - val_accuracy: 0.8595\n",
      "Epoch 518/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8414 - val_loss: 0.3882 - val_accuracy: 0.8591\n",
      "Epoch 519/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8442 - val_loss: 0.3950 - val_accuracy: 0.8603\n",
      "Epoch 520/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8449 - val_loss: 0.4342 - val_accuracy: 0.8610\n",
      "Epoch 521/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8380 - val_loss: 0.3793 - val_accuracy: 0.8565\n",
      "Epoch 522/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8444 - val_loss: 0.3988 - val_accuracy: 0.8561\n",
      "Epoch 523/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3546 - accuracy: 0.8457 - val_loss: 0.3865 - val_accuracy: 0.8610\n",
      "Epoch 524/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3521 - accuracy: 0.8453 - val_loss: 0.3748 - val_accuracy: 0.8576\n",
      "Epoch 525/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8449 - val_loss: 0.3829 - val_accuracy: 0.8603\n",
      "Epoch 526/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8423 - val_loss: 0.3891 - val_accuracy: 0.8565\n",
      "Epoch 527/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8466 - val_loss: 0.4584 - val_accuracy: 0.8588\n",
      "Epoch 528/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8459 - val_loss: 0.3916 - val_accuracy: 0.8561\n",
      "Epoch 529/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8416 - val_loss: 0.3904 - val_accuracy: 0.8569\n",
      "Epoch 530/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8373 - val_loss: 0.3838 - val_accuracy: 0.8519\n",
      "Epoch 531/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8457 - val_loss: 0.3917 - val_accuracy: 0.8565\n",
      "Epoch 532/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8446 - val_loss: 0.4122 - val_accuracy: 0.8478\n",
      "Epoch 533/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8425 - val_loss: 0.4111 - val_accuracy: 0.8542\n",
      "Epoch 534/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3558 - accuracy: 0.8390 - val_loss: 0.4769 - val_accuracy: 0.8504\n",
      "Epoch 535/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8427 - val_loss: 0.3911 - val_accuracy: 0.8535\n",
      "Epoch 536/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8466 - val_loss: 0.3858 - val_accuracy: 0.8576\n",
      "Epoch 537/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8468 - val_loss: 0.4363 - val_accuracy: 0.8576\n",
      "Epoch 538/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8447 - val_loss: 0.3846 - val_accuracy: 0.8565\n",
      "Epoch 539/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8500 - val_loss: 0.4003 - val_accuracy: 0.8599\n",
      "Epoch 540/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8436 - val_loss: 0.4363 - val_accuracy: 0.8550\n",
      "Epoch 541/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8483 - val_loss: 0.4670 - val_accuracy: 0.8580\n",
      "Epoch 542/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8427 - val_loss: 0.4084 - val_accuracy: 0.8538\n",
      "Epoch 543/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8446 - val_loss: 0.3814 - val_accuracy: 0.8493\n",
      "Epoch 544/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8464 - val_loss: 0.3761 - val_accuracy: 0.8603\n",
      "Epoch 545/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8405 - val_loss: 0.3730 - val_accuracy: 0.8603\n",
      "Epoch 546/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8434 - val_loss: 0.3800 - val_accuracy: 0.8489\n",
      "Epoch 547/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8475 - val_loss: 0.3952 - val_accuracy: 0.8599\n",
      "Epoch 548/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8455 - val_loss: 0.3832 - val_accuracy: 0.8610\n",
      "Epoch 549/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8468 - val_loss: 0.3993 - val_accuracy: 0.8591\n",
      "Epoch 550/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8455 - val_loss: 0.3948 - val_accuracy: 0.8580\n",
      "Epoch 551/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8477 - val_loss: 0.3976 - val_accuracy: 0.8588\n",
      "Epoch 552/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8455 - val_loss: 0.3970 - val_accuracy: 0.8519\n",
      "Epoch 553/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8447 - val_loss: 0.4048 - val_accuracy: 0.8463\n",
      "Epoch 554/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3409 - accuracy: 0.8461 - val_loss: 0.3820 - val_accuracy: 0.8546\n",
      "Epoch 555/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8477 - val_loss: 0.4011 - val_accuracy: 0.8573\n",
      "Epoch 556/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8479 - val_loss: 0.3898 - val_accuracy: 0.8603\n",
      "Epoch 557/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8479 - val_loss: 0.4279 - val_accuracy: 0.8557\n",
      "Epoch 558/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8446 - val_loss: 0.4301 - val_accuracy: 0.8554\n",
      "Epoch 559/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8494 - val_loss: 0.3867 - val_accuracy: 0.8535\n",
      "Epoch 560/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8453 - val_loss: 0.4104 - val_accuracy: 0.8508\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8451 - val_loss: 0.3954 - val_accuracy: 0.8550\n",
      "Epoch 562/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8425 - val_loss: 0.4091 - val_accuracy: 0.8576\n",
      "Epoch 563/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8446 - val_loss: 0.5000 - val_accuracy: 0.8497\n",
      "Epoch 564/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8423 - val_loss: 0.3920 - val_accuracy: 0.8451\n",
      "Epoch 565/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8442 - val_loss: 0.4079 - val_accuracy: 0.8554\n",
      "Epoch 566/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8468 - val_loss: 0.4256 - val_accuracy: 0.8569\n",
      "Epoch 567/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8472 - val_loss: 0.4193 - val_accuracy: 0.8432\n",
      "Epoch 568/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8433 - val_loss: 0.4492 - val_accuracy: 0.8569\n",
      "Epoch 569/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8388 - val_loss: 0.4270 - val_accuracy: 0.8497\n",
      "Epoch 570/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8479 - val_loss: 0.4296 - val_accuracy: 0.8531\n",
      "Epoch 571/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8438 - val_loss: 0.4342 - val_accuracy: 0.8546\n",
      "Epoch 572/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8464 - val_loss: 0.4447 - val_accuracy: 0.8569\n",
      "Epoch 573/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8436 - val_loss: 0.3897 - val_accuracy: 0.8603\n",
      "Epoch 574/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8423 - val_loss: 0.4306 - val_accuracy: 0.8580\n",
      "Epoch 575/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8455 - val_loss: 0.4812 - val_accuracy: 0.8557\n",
      "Epoch 576/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8429 - val_loss: 0.5021 - val_accuracy: 0.8557\n",
      "Epoch 577/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8487 - val_loss: 0.3945 - val_accuracy: 0.8504\n",
      "Epoch 578/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8438 - val_loss: 0.4280 - val_accuracy: 0.8489\n",
      "Epoch 579/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8395 - val_loss: 0.3916 - val_accuracy: 0.8565\n",
      "Epoch 580/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8408 - val_loss: 0.3999 - val_accuracy: 0.8573\n",
      "Epoch 581/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8468 - val_loss: 0.3924 - val_accuracy: 0.8523\n",
      "Epoch 582/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8416 - val_loss: 0.3754 - val_accuracy: 0.8576\n",
      "Epoch 583/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3433 - accuracy: 0.8489 - val_loss: 0.4018 - val_accuracy: 0.8546\n",
      "Epoch 584/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8481 - val_loss: 0.4063 - val_accuracy: 0.8459\n",
      "Epoch 585/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8418 - val_loss: 0.4046 - val_accuracy: 0.8413\n",
      "Epoch 586/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8466 - val_loss: 0.4066 - val_accuracy: 0.8595\n",
      "Epoch 587/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8414 - val_loss: 0.3872 - val_accuracy: 0.8576\n",
      "Epoch 588/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8406 - val_loss: 0.4088 - val_accuracy: 0.8591\n",
      "Epoch 589/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8453 - val_loss: 0.3881 - val_accuracy: 0.8569\n",
      "Epoch 590/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8395 - val_loss: 0.3979 - val_accuracy: 0.8451\n",
      "Epoch 591/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8462 - val_loss: 0.4342 - val_accuracy: 0.8599\n",
      "Epoch 592/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8464 - val_loss: 0.4162 - val_accuracy: 0.8584\n",
      "Epoch 593/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8433 - val_loss: 0.4549 - val_accuracy: 0.8580\n",
      "Epoch 594/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8453 - val_loss: 0.4668 - val_accuracy: 0.8550\n",
      "Epoch 595/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8406 - val_loss: 0.4167 - val_accuracy: 0.8542\n",
      "Epoch 596/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8494 - val_loss: 0.4761 - val_accuracy: 0.8542\n",
      "Epoch 597/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8425 - val_loss: 0.4350 - val_accuracy: 0.8508\n",
      "Epoch 598/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8477 - val_loss: 0.3874 - val_accuracy: 0.8538\n",
      "Epoch 599/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8438 - val_loss: 0.4377 - val_accuracy: 0.8554\n",
      "Epoch 600/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8419 - val_loss: 0.4658 - val_accuracy: 0.8569\n",
      "Epoch 601/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8453 - val_loss: 0.4412 - val_accuracy: 0.8595\n",
      "Epoch 602/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8453 - val_loss: 0.4229 - val_accuracy: 0.8485\n",
      "Epoch 603/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8416 - val_loss: 0.4459 - val_accuracy: 0.8584\n",
      "Epoch 604/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8494 - val_loss: 0.4225 - val_accuracy: 0.8546\n",
      "Epoch 605/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8429 - val_loss: 0.4439 - val_accuracy: 0.8395\n",
      "Epoch 606/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8498 - val_loss: 0.4950 - val_accuracy: 0.8550\n",
      "Epoch 607/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8466 - val_loss: 0.4671 - val_accuracy: 0.8538\n",
      "Epoch 608/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8390 - val_loss: 0.4152 - val_accuracy: 0.8538\n",
      "Epoch 609/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8386 - val_loss: 0.4477 - val_accuracy: 0.8531\n",
      "Epoch 610/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8447 - val_loss: 0.4557 - val_accuracy: 0.8535\n",
      "Epoch 611/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8442 - val_loss: 0.4842 - val_accuracy: 0.8413\n",
      "Epoch 612/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8369 - val_loss: 0.4746 - val_accuracy: 0.8406\n",
      "Epoch 613/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8395 - val_loss: 0.4010 - val_accuracy: 0.8542\n",
      "Epoch 614/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8406 - val_loss: 0.3837 - val_accuracy: 0.8527\n",
      "Epoch 615/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8421 - val_loss: 0.3712 - val_accuracy: 0.8519\n",
      "Epoch 616/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8429 - val_loss: 0.3778 - val_accuracy: 0.8546\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8442 - val_loss: 0.3647 - val_accuracy: 0.8550\n",
      "Epoch 618/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8455 - val_loss: 0.3691 - val_accuracy: 0.8542\n",
      "Epoch 619/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8483 - val_loss: 0.3655 - val_accuracy: 0.8459\n",
      "Epoch 620/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8446 - val_loss: 0.3755 - val_accuracy: 0.8474\n",
      "Epoch 621/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8427 - val_loss: 0.3676 - val_accuracy: 0.8557\n",
      "Epoch 622/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8416 - val_loss: 0.3750 - val_accuracy: 0.8523\n",
      "Epoch 623/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8447 - val_loss: 0.3820 - val_accuracy: 0.8576\n",
      "Epoch 624/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8431 - val_loss: 0.3893 - val_accuracy: 0.8561\n",
      "Epoch 625/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8416 - val_loss: 0.4232 - val_accuracy: 0.8588\n",
      "Epoch 626/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3510 - accuracy: 0.8459 - val_loss: 0.4159 - val_accuracy: 0.8523\n",
      "Epoch 627/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8412 - val_loss: 0.4046 - val_accuracy: 0.8569\n",
      "Epoch 628/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3510 - accuracy: 0.8449 - val_loss: 0.3841 - val_accuracy: 0.8554\n",
      "Epoch 629/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8438 - val_loss: 0.4209 - val_accuracy: 0.8569\n",
      "Epoch 630/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8438 - val_loss: 0.3946 - val_accuracy: 0.8550\n",
      "Epoch 631/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8433 - val_loss: 0.4056 - val_accuracy: 0.8557\n",
      "Epoch 632/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8457 - val_loss: 0.4650 - val_accuracy: 0.8538\n",
      "Epoch 633/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8425 - val_loss: 0.4251 - val_accuracy: 0.8538\n",
      "Epoch 634/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8423 - val_loss: 0.4139 - val_accuracy: 0.8516\n",
      "Epoch 635/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8421 - val_loss: 0.3999 - val_accuracy: 0.8576\n",
      "Epoch 636/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8403 - val_loss: 0.3904 - val_accuracy: 0.8550\n",
      "Epoch 637/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8531 - val_loss: 0.4343 - val_accuracy: 0.8538\n",
      "Epoch 638/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8444 - val_loss: 0.3870 - val_accuracy: 0.8550\n",
      "Epoch 639/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8453 - val_loss: 0.3930 - val_accuracy: 0.8463\n",
      "Epoch 640/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8419 - val_loss: 0.3930 - val_accuracy: 0.8535\n",
      "Epoch 641/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8453 - val_loss: 0.3974 - val_accuracy: 0.8523\n",
      "Epoch 642/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8384 - val_loss: 0.4111 - val_accuracy: 0.8535\n",
      "Epoch 643/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8429 - val_loss: 0.4111 - val_accuracy: 0.8584\n",
      "Epoch 644/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8470 - val_loss: 0.4274 - val_accuracy: 0.8603\n",
      "Epoch 645/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8440 - val_loss: 0.4106 - val_accuracy: 0.8542\n",
      "Epoch 646/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8474 - val_loss: 0.3950 - val_accuracy: 0.8489\n",
      "Epoch 647/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8466 - val_loss: 0.4073 - val_accuracy: 0.8546\n",
      "Epoch 648/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8468 - val_loss: 0.3892 - val_accuracy: 0.8512\n",
      "Epoch 649/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8406 - val_loss: 0.4291 - val_accuracy: 0.8542\n",
      "Epoch 650/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8509 - val_loss: 0.4269 - val_accuracy: 0.8516\n",
      "Epoch 651/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8494 - val_loss: 0.4328 - val_accuracy: 0.8538\n",
      "Epoch 652/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8455 - val_loss: 0.4113 - val_accuracy: 0.8289\n",
      "Epoch 653/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8427 - val_loss: 0.5120 - val_accuracy: 0.8319\n",
      "Epoch 654/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8455 - val_loss: 0.4482 - val_accuracy: 0.8542\n",
      "Epoch 655/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8405 - val_loss: 0.4184 - val_accuracy: 0.8535\n",
      "Epoch 656/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8447 - val_loss: 0.3809 - val_accuracy: 0.8557\n",
      "Epoch 657/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8388 - val_loss: 0.4268 - val_accuracy: 0.8603\n",
      "Epoch 658/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8414 - val_loss: 0.4047 - val_accuracy: 0.8554\n",
      "Epoch 659/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8449 - val_loss: 0.4134 - val_accuracy: 0.8569\n",
      "Epoch 660/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8468 - val_loss: 0.4479 - val_accuracy: 0.8569\n",
      "Epoch 661/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8421 - val_loss: 0.4720 - val_accuracy: 0.8535\n",
      "Epoch 662/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8449 - val_loss: 0.5160 - val_accuracy: 0.8557\n",
      "Epoch 663/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8457 - val_loss: 0.4470 - val_accuracy: 0.8523\n",
      "Epoch 664/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8451 - val_loss: 0.3986 - val_accuracy: 0.8554\n",
      "Epoch 665/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8425 - val_loss: 0.4070 - val_accuracy: 0.8535\n",
      "Epoch 666/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8472 - val_loss: 0.3968 - val_accuracy: 0.8557\n",
      "Epoch 667/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.4012 - val_accuracy: 0.8554\n",
      "Epoch 668/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8462 - val_loss: 0.4263 - val_accuracy: 0.8546\n",
      "Epoch 669/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8457 - val_loss: 0.4611 - val_accuracy: 0.8546\n",
      "Epoch 670/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8468 - val_loss: 0.4274 - val_accuracy: 0.8527\n",
      "Epoch 671/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8472 - val_loss: 0.4095 - val_accuracy: 0.8538\n",
      "Epoch 672/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8472 - val_loss: 0.4131 - val_accuracy: 0.8565\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8451 - val_loss: 0.4335 - val_accuracy: 0.8512\n",
      "Epoch 674/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8440 - val_loss: 0.4377 - val_accuracy: 0.8561\n",
      "Epoch 675/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8475 - val_loss: 0.4752 - val_accuracy: 0.8535\n",
      "Epoch 676/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8453 - val_loss: 0.4708 - val_accuracy: 0.8527\n",
      "Epoch 677/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8490 - val_loss: 0.4920 - val_accuracy: 0.8538\n",
      "Epoch 678/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8455 - val_loss: 0.4509 - val_accuracy: 0.8523\n",
      "Epoch 679/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8444 - val_loss: 0.4408 - val_accuracy: 0.8474\n",
      "Epoch 680/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8468 - val_loss: 0.4362 - val_accuracy: 0.8527\n",
      "Epoch 681/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8446 - val_loss: 0.4777 - val_accuracy: 0.8535\n",
      "Epoch 682/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8479 - val_loss: 0.4419 - val_accuracy: 0.8470\n",
      "Epoch 683/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8388 - val_loss: 0.4613 - val_accuracy: 0.8535\n",
      "Epoch 684/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8431 - val_loss: 0.4049 - val_accuracy: 0.8478\n",
      "Epoch 685/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8421 - val_loss: 0.4123 - val_accuracy: 0.8527\n",
      "Epoch 686/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8414 - val_loss: 0.3878 - val_accuracy: 0.8531\n",
      "Epoch 687/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8444 - val_loss: 0.3751 - val_accuracy: 0.8516\n",
      "Epoch 688/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8475 - val_loss: 0.3826 - val_accuracy: 0.8519\n",
      "Epoch 689/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8464 - val_loss: 0.4978 - val_accuracy: 0.8546\n",
      "Epoch 690/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8459 - val_loss: 0.4019 - val_accuracy: 0.8546\n",
      "Epoch 691/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8410 - val_loss: 0.3936 - val_accuracy: 0.8516\n",
      "Epoch 692/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8461 - val_loss: 0.4101 - val_accuracy: 0.8527\n",
      "Epoch 693/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8446 - val_loss: 0.4158 - val_accuracy: 0.8542\n",
      "Epoch 694/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8440 - val_loss: 0.4291 - val_accuracy: 0.8561\n",
      "Epoch 695/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3539 - accuracy: 0.8393 - val_loss: 0.4306 - val_accuracy: 0.8550\n",
      "Epoch 696/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8475 - val_loss: 0.4818 - val_accuracy: 0.8554\n",
      "Epoch 697/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8408 - val_loss: 0.4223 - val_accuracy: 0.8554\n",
      "Epoch 698/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8421 - val_loss: 0.4196 - val_accuracy: 0.8546\n",
      "Epoch 699/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8401 - val_loss: 0.3834 - val_accuracy: 0.8561\n",
      "Epoch 700/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8436 - val_loss: 0.4074 - val_accuracy: 0.8463\n",
      "Epoch 701/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8444 - val_loss: 0.4112 - val_accuracy: 0.8470\n",
      "Epoch 702/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8470 - val_loss: 0.3998 - val_accuracy: 0.8519\n",
      "Epoch 703/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8475 - val_loss: 0.3947 - val_accuracy: 0.8557\n",
      "Epoch 704/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8462 - val_loss: 0.4028 - val_accuracy: 0.8557\n",
      "Epoch 705/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8457 - val_loss: 0.4643 - val_accuracy: 0.8512\n",
      "Epoch 706/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8431 - val_loss: 0.4417 - val_accuracy: 0.8489\n",
      "Epoch 707/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8425 - val_loss: 0.4135 - val_accuracy: 0.8565\n",
      "Epoch 708/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8377 - val_loss: 0.3944 - val_accuracy: 0.8546\n",
      "Epoch 709/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8470 - val_loss: 0.3934 - val_accuracy: 0.8576\n",
      "Epoch 710/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8440 - val_loss: 0.3855 - val_accuracy: 0.8512\n",
      "Epoch 711/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8440 - val_loss: 0.3921 - val_accuracy: 0.8546\n",
      "Epoch 712/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8414 - val_loss: 0.3778 - val_accuracy: 0.8573\n",
      "Epoch 713/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8461 - val_loss: 0.3887 - val_accuracy: 0.8504\n",
      "Epoch 714/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8442 - val_loss: 0.3935 - val_accuracy: 0.8546\n",
      "Epoch 715/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8423 - val_loss: 0.3812 - val_accuracy: 0.8535\n",
      "Epoch 716/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.8446 - val_loss: 0.3969 - val_accuracy: 0.8554\n",
      "Epoch 717/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3550 - accuracy: 0.8434 - val_loss: 0.3834 - val_accuracy: 0.8546\n",
      "Epoch 718/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8380 - val_loss: 0.3866 - val_accuracy: 0.8527\n",
      "Epoch 719/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8421 - val_loss: 0.3908 - val_accuracy: 0.8493\n",
      "Epoch 720/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8405 - val_loss: 0.4356 - val_accuracy: 0.8516\n",
      "Epoch 721/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8461 - val_loss: 0.4130 - val_accuracy: 0.8512\n",
      "Epoch 722/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3408 - accuracy: 0.8399 - val_loss: 0.4354 - val_accuracy: 0.8376\n",
      "Epoch 723/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8474 - val_loss: 0.4028 - val_accuracy: 0.8546\n",
      "Epoch 724/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8449 - val_loss: 0.4276 - val_accuracy: 0.8557\n",
      "Epoch 725/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8472 - val_loss: 0.4916 - val_accuracy: 0.8550\n",
      "Epoch 726/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8440 - val_loss: 0.4320 - val_accuracy: 0.8482\n",
      "Epoch 727/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8405 - val_loss: 0.4010 - val_accuracy: 0.8576\n",
      "Epoch 728/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8446 - val_loss: 0.3951 - val_accuracy: 0.8417\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8462 - val_loss: 0.3941 - val_accuracy: 0.8538\n",
      "Epoch 730/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8423 - val_loss: 0.3967 - val_accuracy: 0.8569\n",
      "Epoch 731/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8449 - val_loss: 0.4424 - val_accuracy: 0.8573\n",
      "Epoch 732/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8390 - val_loss: 0.4009 - val_accuracy: 0.8501\n",
      "Epoch 733/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8399 - val_loss: 0.4675 - val_accuracy: 0.8535\n",
      "Epoch 734/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8429 - val_loss: 0.4074 - val_accuracy: 0.8497\n",
      "Epoch 735/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8410 - val_loss: 0.4589 - val_accuracy: 0.8459\n",
      "Epoch 736/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8364 - val_loss: 0.4323 - val_accuracy: 0.8444\n",
      "Epoch 737/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8442 - val_loss: 0.4470 - val_accuracy: 0.8569\n",
      "Epoch 738/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8408 - val_loss: 0.4730 - val_accuracy: 0.8561\n",
      "Epoch 739/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8446 - val_loss: 0.4530 - val_accuracy: 0.8531\n",
      "Epoch 740/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8438 - val_loss: 0.4683 - val_accuracy: 0.8573\n",
      "Epoch 741/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8464 - val_loss: 0.4013 - val_accuracy: 0.8554\n",
      "Epoch 742/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8447 - val_loss: 0.3905 - val_accuracy: 0.8588\n",
      "Epoch 743/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8434 - val_loss: 0.4182 - val_accuracy: 0.8557\n",
      "Epoch 744/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8403 - val_loss: 0.4217 - val_accuracy: 0.8425\n",
      "Epoch 745/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8401 - val_loss: 0.4513 - val_accuracy: 0.8485\n",
      "Epoch 746/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.8382 - val_loss: 0.4211 - val_accuracy: 0.8573\n",
      "Epoch 747/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8468 - val_loss: 0.4006 - val_accuracy: 0.8383\n",
      "Epoch 748/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8457 - val_loss: 0.4262 - val_accuracy: 0.8565\n",
      "Epoch 749/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3512 - accuracy: 0.8393 - val_loss: 0.4207 - val_accuracy: 0.8542\n",
      "Epoch 750/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8466 - val_loss: 0.4116 - val_accuracy: 0.8569\n",
      "Epoch 751/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3427 - accuracy: 0.8427 - val_loss: 0.4964 - val_accuracy: 0.8569\n",
      "Epoch 752/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8434 - val_loss: 0.3792 - val_accuracy: 0.8595\n",
      "Epoch 753/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8464 - val_loss: 0.4130 - val_accuracy: 0.8565\n",
      "Epoch 754/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8423 - val_loss: 0.4550 - val_accuracy: 0.8508\n",
      "Epoch 755/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8412 - val_loss: 0.4111 - val_accuracy: 0.8588\n",
      "Epoch 756/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8427 - val_loss: 0.4429 - val_accuracy: 0.8576\n",
      "Epoch 757/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8434 - val_loss: 0.4574 - val_accuracy: 0.8535\n",
      "Epoch 758/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3578 - accuracy: 0.8418 - val_loss: 0.4135 - val_accuracy: 0.8531\n",
      "Epoch 759/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8449 - val_loss: 0.4712 - val_accuracy: 0.8535\n",
      "Epoch 760/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8466 - val_loss: 0.4909 - val_accuracy: 0.8531\n",
      "Epoch 761/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8436 - val_loss: 0.4370 - val_accuracy: 0.8504\n",
      "Epoch 762/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8421 - val_loss: 0.4789 - val_accuracy: 0.8573\n",
      "Epoch 763/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8414 - val_loss: 0.4653 - val_accuracy: 0.8474\n",
      "Epoch 764/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8434 - val_loss: 0.4234 - val_accuracy: 0.8565\n",
      "Epoch 765/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8433 - val_loss: 0.3830 - val_accuracy: 0.8561\n",
      "Epoch 766/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8431 - val_loss: 0.4033 - val_accuracy: 0.8565\n",
      "Epoch 767/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8440 - val_loss: 0.4354 - val_accuracy: 0.8538\n",
      "Epoch 768/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8442 - val_loss: 0.4248 - val_accuracy: 0.8550\n",
      "Epoch 769/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8425 - val_loss: 0.3825 - val_accuracy: 0.8349\n",
      "Epoch 770/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8447 - val_loss: 0.4094 - val_accuracy: 0.8561\n",
      "Epoch 771/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8470 - val_loss: 0.4234 - val_accuracy: 0.8554\n",
      "Epoch 772/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8455 - val_loss: 0.3936 - val_accuracy: 0.8550\n",
      "Epoch 773/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8481 - val_loss: 0.4646 - val_accuracy: 0.8508\n",
      "Epoch 774/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.8425 - val_loss: 0.4253 - val_accuracy: 0.8527\n",
      "Epoch 775/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8393 - val_loss: 0.3995 - val_accuracy: 0.8535\n",
      "Epoch 776/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8390 - val_loss: 0.4445 - val_accuracy: 0.8550\n",
      "Epoch 777/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8447 - val_loss: 0.4112 - val_accuracy: 0.8489\n",
      "Epoch 778/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3420 - accuracy: 0.8440 - val_loss: 0.4298 - val_accuracy: 0.8459\n",
      "Epoch 779/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8410 - val_loss: 0.4107 - val_accuracy: 0.8538\n",
      "Epoch 780/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8457 - val_loss: 0.4518 - val_accuracy: 0.8542\n",
      "Epoch 781/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8457 - val_loss: 0.4301 - val_accuracy: 0.8580\n",
      "Epoch 782/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8502 - val_loss: 0.4363 - val_accuracy: 0.8565\n",
      "Epoch 783/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8459 - val_loss: 0.4321 - val_accuracy: 0.8527\n",
      "Epoch 784/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8431 - val_loss: 0.4003 - val_accuracy: 0.8523\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8434 - val_loss: 0.4586 - val_accuracy: 0.8546\n",
      "Epoch 786/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8449 - val_loss: 0.4359 - val_accuracy: 0.8546\n",
      "Epoch 787/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8462 - val_loss: 0.4518 - val_accuracy: 0.8508\n",
      "Epoch 788/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8433 - val_loss: 0.5011 - val_accuracy: 0.8576\n",
      "Epoch 789/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8412 - val_loss: 0.4106 - val_accuracy: 0.8417\n",
      "Epoch 790/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8410 - val_loss: 0.4434 - val_accuracy: 0.8459\n",
      "Epoch 791/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8421 - val_loss: 0.4340 - val_accuracy: 0.8554\n",
      "Epoch 792/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8472 - val_loss: 0.3954 - val_accuracy: 0.8538\n",
      "Epoch 793/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8438 - val_loss: 0.4515 - val_accuracy: 0.8565\n",
      "Epoch 794/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8412 - val_loss: 0.4281 - val_accuracy: 0.8463\n",
      "Epoch 795/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8386 - val_loss: 0.4763 - val_accuracy: 0.8474\n",
      "Epoch 796/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8481 - val_loss: 0.4334 - val_accuracy: 0.8535\n",
      "Epoch 797/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8462 - val_loss: 0.4122 - val_accuracy: 0.8429\n",
      "Epoch 798/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8464 - val_loss: 0.5001 - val_accuracy: 0.8519\n",
      "Epoch 799/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8451 - val_loss: 0.5124 - val_accuracy: 0.8474\n",
      "Epoch 800/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8388 - val_loss: 0.4152 - val_accuracy: 0.8455\n",
      "Epoch 801/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3525 - accuracy: 0.8421 - val_loss: 0.4099 - val_accuracy: 0.8523\n",
      "Epoch 802/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8429 - val_loss: 0.4318 - val_accuracy: 0.8523\n",
      "Epoch 803/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3398 - accuracy: 0.8466 - val_loss: 0.4498 - val_accuracy: 0.8410\n",
      "Epoch 804/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8371 - val_loss: 0.4383 - val_accuracy: 0.8550\n",
      "Epoch 805/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8459 - val_loss: 0.4611 - val_accuracy: 0.8542\n",
      "Epoch 806/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3556 - accuracy: 0.8438 - val_loss: 0.4243 - val_accuracy: 0.8531\n",
      "Epoch 807/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8414 - val_loss: 0.4232 - val_accuracy: 0.8542\n",
      "Epoch 808/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3541 - accuracy: 0.8449 - val_loss: 0.4187 - val_accuracy: 0.8550\n",
      "Epoch 809/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8449 - val_loss: 0.4446 - val_accuracy: 0.8580\n",
      "Epoch 810/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8429 - val_loss: 0.4950 - val_accuracy: 0.8573\n",
      "Epoch 811/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8500 - val_loss: 0.4494 - val_accuracy: 0.8610\n",
      "Epoch 812/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8447 - val_loss: 0.3898 - val_accuracy: 0.8603\n",
      "Epoch 813/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8440 - val_loss: 0.4057 - val_accuracy: 0.8588\n",
      "Epoch 814/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8447 - val_loss: 0.3935 - val_accuracy: 0.8591\n",
      "Epoch 815/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8472 - val_loss: 0.4146 - val_accuracy: 0.8421\n",
      "Epoch 816/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8438 - val_loss: 0.5119 - val_accuracy: 0.8527\n",
      "Epoch 817/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8444 - val_loss: 0.4012 - val_accuracy: 0.8535\n",
      "Epoch 818/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8440 - val_loss: 0.4852 - val_accuracy: 0.8561\n",
      "Epoch 819/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8475 - val_loss: 0.5177 - val_accuracy: 0.8561\n",
      "Epoch 820/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8446 - val_loss: 0.4236 - val_accuracy: 0.8584\n",
      "Epoch 821/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8425 - val_loss: 0.4455 - val_accuracy: 0.8538\n",
      "Epoch 822/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8444 - val_loss: 0.4974 - val_accuracy: 0.8512\n",
      "Epoch 823/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8401 - val_loss: 0.5034 - val_accuracy: 0.8531\n",
      "Epoch 824/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3555 - accuracy: 0.8442 - val_loss: 0.4547 - val_accuracy: 0.8538\n",
      "Epoch 825/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3480 - accuracy: 0.8433 - val_loss: 0.4666 - val_accuracy: 0.8519\n",
      "Epoch 826/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3493 - accuracy: 0.8419 - val_loss: 0.4563 - val_accuracy: 0.8565\n",
      "Epoch 827/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8414 - val_loss: 0.4173 - val_accuracy: 0.8565\n",
      "Epoch 828/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8447 - val_loss: 0.4218 - val_accuracy: 0.8501\n",
      "Epoch 829/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8451 - val_loss: 0.4292 - val_accuracy: 0.8474\n",
      "Epoch 830/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8410 - val_loss: 0.4132 - val_accuracy: 0.8451\n",
      "Epoch 831/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8408 - val_loss: 0.5397 - val_accuracy: 0.8508\n",
      "Epoch 832/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3531 - accuracy: 0.8391 - val_loss: 0.5025 - val_accuracy: 0.8504\n",
      "Epoch 833/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8433 - val_loss: 0.4883 - val_accuracy: 0.8508\n",
      "Epoch 834/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8461 - val_loss: 0.4415 - val_accuracy: 0.8519\n",
      "Epoch 835/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8474 - val_loss: 0.4593 - val_accuracy: 0.8417\n",
      "Epoch 836/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8449 - val_loss: 0.4375 - val_accuracy: 0.8535\n",
      "Epoch 837/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8427 - val_loss: 0.4334 - val_accuracy: 0.8542\n",
      "Epoch 838/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8492 - val_loss: 0.4659 - val_accuracy: 0.8527\n",
      "Epoch 839/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8444 - val_loss: 0.5351 - val_accuracy: 0.8554\n",
      "Epoch 840/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8511 - val_loss: 0.4779 - val_accuracy: 0.8546\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8503 - val_loss: 0.4906 - val_accuracy: 0.8557\n",
      "Epoch 842/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8487 - val_loss: 0.4819 - val_accuracy: 0.8482\n",
      "Epoch 843/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8470 - val_loss: 0.5000 - val_accuracy: 0.8557\n",
      "Epoch 844/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8490 - val_loss: 0.4714 - val_accuracy: 0.8554\n",
      "Epoch 845/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8492 - val_loss: 0.4610 - val_accuracy: 0.8531\n",
      "Epoch 846/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8449 - val_loss: 0.5932 - val_accuracy: 0.8565\n",
      "Epoch 847/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3532 - accuracy: 0.8464 - val_loss: 0.4368 - val_accuracy: 0.8531\n",
      "Epoch 848/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8438 - val_loss: 0.4520 - val_accuracy: 0.8573\n",
      "Epoch 849/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3508 - accuracy: 0.8462 - val_loss: 0.4644 - val_accuracy: 0.8554\n",
      "Epoch 850/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8530 - val_loss: 0.4103 - val_accuracy: 0.8402\n",
      "Epoch 851/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8503 - val_loss: 0.5204 - val_accuracy: 0.8569\n",
      "Epoch 852/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8447 - val_loss: 0.3996 - val_accuracy: 0.8603\n",
      "Epoch 853/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8449 - val_loss: 0.4522 - val_accuracy: 0.8554\n",
      "Epoch 854/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3494 - accuracy: 0.8419 - val_loss: 0.4331 - val_accuracy: 0.8557\n",
      "Epoch 855/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8419 - val_loss: 0.4048 - val_accuracy: 0.8542\n",
      "Epoch 856/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8440 - val_loss: 0.4308 - val_accuracy: 0.8531\n",
      "Epoch 857/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3487 - accuracy: 0.8455 - val_loss: 0.5070 - val_accuracy: 0.8323\n",
      "Epoch 858/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8466 - val_loss: 0.4487 - val_accuracy: 0.8512\n",
      "Epoch 859/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8468 - val_loss: 0.5357 - val_accuracy: 0.8554\n",
      "Epoch 860/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8423 - val_loss: 0.5226 - val_accuracy: 0.8523\n",
      "Epoch 861/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8444 - val_loss: 0.4615 - val_accuracy: 0.8531\n",
      "Epoch 862/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8464 - val_loss: 0.4953 - val_accuracy: 0.8523\n",
      "Epoch 863/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8427 - val_loss: 0.4636 - val_accuracy: 0.8531\n",
      "Epoch 864/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8419 - val_loss: 0.5403 - val_accuracy: 0.8538\n",
      "Epoch 865/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8475 - val_loss: 0.4768 - val_accuracy: 0.8523\n",
      "Epoch 866/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8457 - val_loss: 0.4745 - val_accuracy: 0.8501\n",
      "Epoch 867/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8479 - val_loss: 0.4566 - val_accuracy: 0.8504\n",
      "Epoch 868/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8455 - val_loss: 0.4062 - val_accuracy: 0.8398\n",
      "Epoch 869/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8440 - val_loss: 0.3923 - val_accuracy: 0.8546\n",
      "Epoch 870/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8459 - val_loss: 0.4460 - val_accuracy: 0.8519\n",
      "Epoch 871/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8447 - val_loss: 0.4132 - val_accuracy: 0.8535\n",
      "Epoch 872/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8474 - val_loss: 0.4025 - val_accuracy: 0.8516\n",
      "Epoch 873/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8479 - val_loss: 0.4021 - val_accuracy: 0.8542\n",
      "Epoch 874/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8462 - val_loss: 0.3993 - val_accuracy: 0.8531\n",
      "Epoch 875/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8494 - val_loss: 0.4502 - val_accuracy: 0.8550\n",
      "Epoch 876/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8446 - val_loss: 0.3839 - val_accuracy: 0.8569\n",
      "Epoch 877/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8455 - val_loss: 0.4090 - val_accuracy: 0.8542\n",
      "Epoch 878/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8470 - val_loss: 0.4281 - val_accuracy: 0.8538\n",
      "Epoch 879/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8438 - val_loss: 0.4763 - val_accuracy: 0.8565\n",
      "Epoch 880/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8433 - val_loss: 0.4037 - val_accuracy: 0.8546\n",
      "Epoch 881/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3419 - accuracy: 0.8470 - val_loss: 0.5428 - val_accuracy: 0.8580\n",
      "Epoch 882/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3513 - accuracy: 0.8427 - val_loss: 0.5050 - val_accuracy: 0.8584\n",
      "Epoch 883/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8433 - val_loss: 0.4171 - val_accuracy: 0.8425\n",
      "Epoch 884/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8416 - val_loss: 0.4122 - val_accuracy: 0.8573\n",
      "Epoch 885/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8444 - val_loss: 0.4700 - val_accuracy: 0.8557\n",
      "Epoch 886/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8472 - val_loss: 0.4121 - val_accuracy: 0.8561\n",
      "Epoch 887/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8434 - val_loss: 0.4273 - val_accuracy: 0.8527\n",
      "Epoch 888/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8449 - val_loss: 0.3973 - val_accuracy: 0.8573\n",
      "Epoch 889/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8451 - val_loss: 0.4568 - val_accuracy: 0.8580\n",
      "Epoch 890/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3524 - accuracy: 0.8440 - val_loss: 0.4411 - val_accuracy: 0.8584\n",
      "Epoch 891/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8453 - val_loss: 0.4154 - val_accuracy: 0.8591\n",
      "Epoch 892/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8487 - val_loss: 0.4104 - val_accuracy: 0.8569\n",
      "Epoch 893/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8468 - val_loss: 0.4351 - val_accuracy: 0.8573\n",
      "Epoch 894/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8427 - val_loss: 0.4072 - val_accuracy: 0.8576\n",
      "Epoch 895/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3508 - accuracy: 0.8457 - val_loss: 0.3898 - val_accuracy: 0.8535\n",
      "Epoch 896/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8416 - val_loss: 0.4480 - val_accuracy: 0.8527\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8455 - val_loss: 0.4585 - val_accuracy: 0.8542\n",
      "Epoch 898/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8461 - val_loss: 0.4185 - val_accuracy: 0.8569\n",
      "Epoch 899/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8436 - val_loss: 0.4396 - val_accuracy: 0.8550\n",
      "Epoch 900/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8492 - val_loss: 0.4185 - val_accuracy: 0.8546\n",
      "Epoch 901/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3536 - accuracy: 0.8446 - val_loss: 0.4154 - val_accuracy: 0.8561\n",
      "Epoch 902/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.8440 - val_loss: 0.5406 - val_accuracy: 0.8576\n",
      "Epoch 903/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8466 - val_loss: 0.4554 - val_accuracy: 0.8584\n",
      "Epoch 904/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8414 - val_loss: 0.4717 - val_accuracy: 0.8565\n",
      "Epoch 905/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8487 - val_loss: 0.4451 - val_accuracy: 0.8573\n",
      "Epoch 906/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8485 - val_loss: 0.4630 - val_accuracy: 0.8391\n",
      "Epoch 907/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8470 - val_loss: 0.4667 - val_accuracy: 0.8591\n",
      "Epoch 908/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8474 - val_loss: 0.5497 - val_accuracy: 0.8569\n",
      "Epoch 909/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3481 - accuracy: 0.8474 - val_loss: 0.4477 - val_accuracy: 0.8599\n",
      "Epoch 910/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3548 - accuracy: 0.8475 - val_loss: 0.4411 - val_accuracy: 0.8561\n",
      "Epoch 911/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8489 - val_loss: 0.4482 - val_accuracy: 0.8542\n",
      "Epoch 912/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8489 - val_loss: 0.4239 - val_accuracy: 0.8573\n",
      "Epoch 913/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8453 - val_loss: 0.4271 - val_accuracy: 0.8542\n",
      "Epoch 914/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3508 - accuracy: 0.8440 - val_loss: 0.4884 - val_accuracy: 0.8573\n",
      "Epoch 915/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8449 - val_loss: 0.5360 - val_accuracy: 0.8538\n",
      "Epoch 916/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8507 - val_loss: 0.4563 - val_accuracy: 0.8573\n",
      "Epoch 917/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8490 - val_loss: 0.5948 - val_accuracy: 0.8561\n",
      "Epoch 918/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8414 - val_loss: 0.4528 - val_accuracy: 0.8573\n",
      "Epoch 919/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8395 - val_loss: 0.6643 - val_accuracy: 0.8561\n",
      "Epoch 920/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8444 - val_loss: 0.5192 - val_accuracy: 0.8569\n",
      "Epoch 921/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3459 - accuracy: 0.8505 - val_loss: 0.5305 - val_accuracy: 0.8607\n",
      "Epoch 922/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.8423 - val_loss: 0.4110 - val_accuracy: 0.8538\n",
      "Epoch 923/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8382 - val_loss: 0.4298 - val_accuracy: 0.8561\n",
      "Epoch 924/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8481 - val_loss: 0.4677 - val_accuracy: 0.8535\n",
      "Epoch 925/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8406 - val_loss: 0.4216 - val_accuracy: 0.8527\n",
      "Epoch 926/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8427 - val_loss: 0.4878 - val_accuracy: 0.8546\n",
      "Epoch 927/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8475 - val_loss: 0.5232 - val_accuracy: 0.8554\n",
      "Epoch 928/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8459 - val_loss: 0.4436 - val_accuracy: 0.8527\n",
      "Epoch 929/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3437 - accuracy: 0.8475 - val_loss: 0.4304 - val_accuracy: 0.8535\n",
      "Epoch 930/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8468 - val_loss: 0.3964 - val_accuracy: 0.8516\n",
      "Epoch 931/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8438 - val_loss: 0.4658 - val_accuracy: 0.8516\n",
      "Epoch 932/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8449 - val_loss: 0.4589 - val_accuracy: 0.8535\n",
      "Epoch 933/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8442 - val_loss: 0.4401 - val_accuracy: 0.8557\n",
      "Epoch 934/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3444 - accuracy: 0.8464 - val_loss: 0.5766 - val_accuracy: 0.8527\n",
      "Epoch 935/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8436 - val_loss: 0.4569 - val_accuracy: 0.8527\n",
      "Epoch 936/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3454 - accuracy: 0.8472 - val_loss: 0.4858 - val_accuracy: 0.8527\n",
      "Epoch 937/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3508 - accuracy: 0.8421 - val_loss: 0.4328 - val_accuracy: 0.8516\n",
      "Epoch 938/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8461 - val_loss: 0.3973 - val_accuracy: 0.8546\n",
      "Epoch 939/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8462 - val_loss: 0.4424 - val_accuracy: 0.8580\n",
      "Epoch 940/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8466 - val_loss: 0.4134 - val_accuracy: 0.8573\n",
      "Epoch 941/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8451 - val_loss: 0.4107 - val_accuracy: 0.8595\n",
      "Epoch 942/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8474 - val_loss: 0.4536 - val_accuracy: 0.8584\n",
      "Epoch 943/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8485 - val_loss: 0.4309 - val_accuracy: 0.8599\n",
      "Epoch 944/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8470 - val_loss: 0.4621 - val_accuracy: 0.8588\n",
      "Epoch 945/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3445 - accuracy: 0.8446 - val_loss: 0.4388 - val_accuracy: 0.8584\n",
      "Epoch 946/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8468 - val_loss: 0.4215 - val_accuracy: 0.8573\n",
      "Epoch 947/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8446 - val_loss: 0.4223 - val_accuracy: 0.8482\n",
      "Epoch 948/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8412 - val_loss: 0.3906 - val_accuracy: 0.8550\n",
      "Epoch 949/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8446 - val_loss: 0.3951 - val_accuracy: 0.8576\n",
      "Epoch 950/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8485 - val_loss: 0.4650 - val_accuracy: 0.8569\n",
      "Epoch 951/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3497 - accuracy: 0.8399 - val_loss: 0.4703 - val_accuracy: 0.8504\n",
      "Epoch 952/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3483 - accuracy: 0.8436 - val_loss: 0.4431 - val_accuracy: 0.8565\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3451 - accuracy: 0.8438 - val_loss: 0.5631 - val_accuracy: 0.8538\n",
      "Epoch 954/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3470 - accuracy: 0.8451 - val_loss: 0.4792 - val_accuracy: 0.8531\n",
      "Epoch 955/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8466 - val_loss: 0.4878 - val_accuracy: 0.8538\n",
      "Epoch 956/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8474 - val_loss: 0.4377 - val_accuracy: 0.8550\n",
      "Epoch 957/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8457 - val_loss: 0.4021 - val_accuracy: 0.8535\n",
      "Epoch 958/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8466 - val_loss: 0.4031 - val_accuracy: 0.8429\n",
      "Epoch 959/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8500 - val_loss: 0.4184 - val_accuracy: 0.8573\n",
      "Epoch 960/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8475 - val_loss: 0.4135 - val_accuracy: 0.8546\n",
      "Epoch 961/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8498 - val_loss: 0.4844 - val_accuracy: 0.8546\n",
      "Epoch 962/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3415 - accuracy: 0.8509 - val_loss: 0.4612 - val_accuracy: 0.8557\n",
      "Epoch 963/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8459 - val_loss: 0.4686 - val_accuracy: 0.8569\n",
      "Epoch 964/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8468 - val_loss: 0.4641 - val_accuracy: 0.8550\n",
      "Epoch 965/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8487 - val_loss: 0.5289 - val_accuracy: 0.8561\n",
      "Epoch 966/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8481 - val_loss: 0.5226 - val_accuracy: 0.8584\n",
      "Epoch 967/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8477 - val_loss: 0.4497 - val_accuracy: 0.8546\n",
      "Epoch 968/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8459 - val_loss: 0.4300 - val_accuracy: 0.8561\n",
      "Epoch 969/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8406 - val_loss: 0.4365 - val_accuracy: 0.8542\n",
      "Epoch 970/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8431 - val_loss: 0.4504 - val_accuracy: 0.8584\n",
      "Epoch 971/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8502 - val_loss: 0.4192 - val_accuracy: 0.8569\n",
      "Epoch 972/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3478 - accuracy: 0.8440 - val_loss: 0.4455 - val_accuracy: 0.8580\n",
      "Epoch 973/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3566 - accuracy: 0.8395 - val_loss: 0.4094 - val_accuracy: 0.8576\n",
      "Epoch 974/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8438 - val_loss: 0.4326 - val_accuracy: 0.8523\n",
      "Epoch 975/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8444 - val_loss: 0.4128 - val_accuracy: 0.8561\n",
      "Epoch 976/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8418 - val_loss: 0.3810 - val_accuracy: 0.8573\n",
      "Epoch 977/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8483 - val_loss: 0.3872 - val_accuracy: 0.8573\n",
      "Epoch 978/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8414 - val_loss: 0.4119 - val_accuracy: 0.8557\n",
      "Epoch 979/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8457 - val_loss: 0.4708 - val_accuracy: 0.8531\n",
      "Epoch 980/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8453 - val_loss: 0.4015 - val_accuracy: 0.8554\n",
      "Epoch 981/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8472 - val_loss: 0.4773 - val_accuracy: 0.8538\n",
      "Epoch 982/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8453 - val_loss: 0.5054 - val_accuracy: 0.8546\n",
      "Epoch 983/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8446 - val_loss: 0.4400 - val_accuracy: 0.8591\n",
      "Epoch 984/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8487 - val_loss: 0.4216 - val_accuracy: 0.8561\n",
      "Epoch 985/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8446 - val_loss: 0.4275 - val_accuracy: 0.8429\n",
      "Epoch 986/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8483 - val_loss: 0.4922 - val_accuracy: 0.8535\n",
      "Epoch 987/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3431 - accuracy: 0.8449 - val_loss: 0.4228 - val_accuracy: 0.8584\n",
      "Epoch 988/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8425 - val_loss: 0.4246 - val_accuracy: 0.8595\n",
      "Epoch 989/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3508 - accuracy: 0.8462 - val_loss: 0.3981 - val_accuracy: 0.8497\n",
      "Epoch 990/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3507 - accuracy: 0.8429 - val_loss: 0.3957 - val_accuracy: 0.8554\n",
      "Epoch 991/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8446 - val_loss: 0.4249 - val_accuracy: 0.8599\n",
      "Epoch 992/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8468 - val_loss: 0.4480 - val_accuracy: 0.8595\n",
      "Epoch 993/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8449 - val_loss: 0.4430 - val_accuracy: 0.8561\n",
      "Epoch 994/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3473 - accuracy: 0.8444 - val_loss: 0.4273 - val_accuracy: 0.8281\n",
      "Epoch 995/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8470 - val_loss: 0.5093 - val_accuracy: 0.8482\n",
      "Epoch 996/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3456 - accuracy: 0.8440 - val_loss: 0.4537 - val_accuracy: 0.8588\n",
      "Epoch 997/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3520 - accuracy: 0.8438 - val_loss: 0.4738 - val_accuracy: 0.8580\n",
      "Epoch 998/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8479 - val_loss: 0.4233 - val_accuracy: 0.8569\n",
      "Epoch 999/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8500 - val_loss: 0.4726 - val_accuracy: 0.8554\n",
      "Epoch 1000/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8433 - val_loss: 0.4288 - val_accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "model_history = classifier.fit(X_train, y_train, validation_split = .33, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cbd040aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "5a4c2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We can add an early stopping to our model so that it stops the model when the accuracy is not increasing. Copied from the keras website.\n",
    "import tensorflow as tf\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "fcb3a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "536/536 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.7990 - val_loss: 0.3768 - val_accuracy: 0.8183\n",
      "Epoch 2/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3907 - accuracy: 0.8259 - val_loss: 0.3650 - val_accuracy: 0.8538\n",
      "Epoch 3/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3736 - accuracy: 0.8423 - val_loss: 0.3657 - val_accuracy: 0.8410\n",
      "Epoch 4/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3694 - accuracy: 0.8464 - val_loss: 0.3662 - val_accuracy: 0.8512\n",
      "Epoch 5/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3698 - accuracy: 0.8451 - val_loss: 0.3512 - val_accuracy: 0.8576\n",
      "Epoch 6/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8526 - val_loss: 0.3600 - val_accuracy: 0.8531\n",
      "Epoch 7/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8539 - val_loss: 0.3497 - val_accuracy: 0.8607\n",
      "Epoch 8/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3585 - accuracy: 0.8530 - val_loss: 0.3602 - val_accuracy: 0.8523\n",
      "Epoch 9/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8615 - val_loss: 0.3471 - val_accuracy: 0.8660\n",
      "Epoch 10/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8554 - val_loss: 0.3716 - val_accuracy: 0.8254\n",
      "Epoch 11/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8546 - val_loss: 0.3466 - val_accuracy: 0.8618\n",
      "Epoch 12/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8600 - val_loss: 0.3479 - val_accuracy: 0.8561\n",
      "Epoch 13/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8565 - val_loss: 0.3524 - val_accuracy: 0.8588\n",
      "Epoch 14/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.8597 - val_loss: 0.3544 - val_accuracy: 0.8591\n",
      "Epoch 15/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3543 - accuracy: 0.8524 - val_loss: 0.3770 - val_accuracy: 0.8474\n",
      "Epoch 16/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8580 - val_loss: 0.3480 - val_accuracy: 0.8607\n",
      "Epoch 17/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3492 - accuracy: 0.8561 - val_loss: 0.3459 - val_accuracy: 0.8618\n",
      "Epoch 18/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8558 - val_loss: 0.3582 - val_accuracy: 0.8497\n",
      "Epoch 19/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8606 - val_loss: 0.3686 - val_accuracy: 0.8501\n",
      "Epoch 20/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8587 - val_loss: 0.3517 - val_accuracy: 0.8561\n",
      "Epoch 21/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8574 - val_loss: 0.3526 - val_accuracy: 0.8554\n",
      "Epoch 22/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8545 - val_loss: 0.3503 - val_accuracy: 0.8576\n",
      "Epoch 23/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8599 - val_loss: 0.3515 - val_accuracy: 0.8610\n",
      "Epoch 24/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8595 - val_loss: 0.3479 - val_accuracy: 0.8588\n",
      "Epoch 25/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8578 - val_loss: 0.3564 - val_accuracy: 0.8554\n",
      "Epoch 26/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3466 - accuracy: 0.8606 - val_loss: 0.3566 - val_accuracy: 0.8519\n",
      "Epoch 27/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8597 - val_loss: 0.3488 - val_accuracy: 0.8584\n",
      "Epoch 28/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8593 - val_loss: 0.3647 - val_accuracy: 0.8376\n",
      "Epoch 29/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8567 - val_loss: 0.3503 - val_accuracy: 0.8569\n",
      "Epoch 30/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8612 - val_loss: 0.3466 - val_accuracy: 0.8626\n",
      "Epoch 31/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8569 - val_loss: 0.3613 - val_accuracy: 0.8402\n",
      "Epoch 32/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.8561 - val_loss: 0.3466 - val_accuracy: 0.8569\n",
      "Epoch 33/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3438 - accuracy: 0.8600 - val_loss: 0.3409 - val_accuracy: 0.8546\n",
      "Epoch 34/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8589 - val_loss: 0.3561 - val_accuracy: 0.8527\n",
      "Epoch 35/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8563 - val_loss: 0.3477 - val_accuracy: 0.8546\n",
      "Epoch 36/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8561 - val_loss: 0.3451 - val_accuracy: 0.8576\n",
      "Epoch 37/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8539 - val_loss: 0.3446 - val_accuracy: 0.8580\n",
      "Epoch 38/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8615 - val_loss: 0.3378 - val_accuracy: 0.8644\n",
      "Epoch 39/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8593 - val_loss: 0.3617 - val_accuracy: 0.8413\n",
      "Epoch 40/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3403 - accuracy: 0.8580 - val_loss: 0.3517 - val_accuracy: 0.8588\n",
      "Epoch 41/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3475 - accuracy: 0.8599 - val_loss: 0.3508 - val_accuracy: 0.8576\n",
      "Epoch 42/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3479 - accuracy: 0.8587 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "536/536 [==============================] - 2s 4ms/step - loss: 0.3436 - accuracy: 0.8597 - val_loss: 0.3606 - val_accuracy: 0.8474\n",
      "Epoch 44/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8614 - val_loss: 0.3598 - val_accuracy: 0.8519\n",
      "Epoch 45/1000\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3457 - accuracy: 0.8552 - val_loss: 0.3591 - val_accuracy: 0.8523\n",
      "Epoch 46/1000\n",
      "536/536 [==============================] - 2s 4ms/step - loss: 0.3414 - accuracy: 0.8608 - val_loss: 0.3684 - val_accuracy: 0.8406\n",
      "Epoch 47/1000\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3363 - accuracy: 0.8591 - val_loss: 0.3451 - val_accuracy: 0.8644\n",
      "Epoch 48/1000\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3423 - accuracy: 0.8543 - val_loss: 0.3430 - val_accuracy: 0.8629\n",
      "Epoch 49/1000\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3400 - accuracy: 0.8586 - val_loss: 0.3401 - val_accuracy: 0.8603\n",
      "Epoch 50/1000\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8617 - val_loss: 0.3451 - val_accuracy: 0.8614\n",
      "Epoch 51/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8636 - val_loss: 0.3422 - val_accuracy: 0.8626\n",
      "Epoch 52/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8600 - val_loss: 0.3518 - val_accuracy: 0.8531\n",
      "Epoch 53/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8604 - val_loss: 0.3388 - val_accuracy: 0.8614\n",
      "Epoch 54/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8604 - val_loss: 0.3503 - val_accuracy: 0.8618\n",
      "Epoch 55/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8578 - val_loss: 0.3462 - val_accuracy: 0.8610\n",
      "Epoch 56/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8619 - val_loss: 0.3426 - val_accuracy: 0.8626\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8599 - val_loss: 0.3571 - val_accuracy: 0.8538\n",
      "Epoch 58/1000\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8556 - val_loss: 0.3502 - val_accuracy: 0.8546\n",
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_history = classifier.fit(X_train, y_train, validation_split = .33, batch_size = 10, epochs = 1000, callbacks = early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5aa62d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "104e6b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8421347141265869,\n",
       " 0.8419481515884399,\n",
       " 0.8385893106460571,\n",
       " 0.8454935550689697,\n",
       " 0.8412017226219177,\n",
       " 0.8464265465736389,\n",
       " 0.8404552936553955,\n",
       " 0.8445605635643005,\n",
       " 0.8395223021507263,\n",
       " 0.8423213362693787,\n",
       " 0.8425079584121704,\n",
       " 0.844187319278717,\n",
       " 0.8380295038223267,\n",
       " 0.8443739414215088,\n",
       " 0.8426945209503174,\n",
       " 0.8454935550689697,\n",
       " 0.8432543277740479,\n",
       " 0.8395223021507263,\n",
       " 0.8471729755401611,\n",
       " 0.839895486831665,\n",
       " 0.8428811430931091,\n",
       " 0.8456801772117615,\n",
       " 0.839895486831665,\n",
       " 0.8382160663604736,\n",
       " 0.8380295038223267,\n",
       " 0.8434409499168396,\n",
       " 0.8423213362693787]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e8aa447d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8527073264122009,\n",
       " 0.8572510480880737,\n",
       " 0.8564937710762024,\n",
       " 0.857629656791687,\n",
       " 0.8527073264122009,\n",
       " 0.8477849364280701,\n",
       " 0.857629656791687,\n",
       " 0.857629656791687,\n",
       " 0.8421052694320679,\n",
       " 0.8546005487442017,\n",
       " 0.8587656021118164,\n",
       " 0.8443771004676819,\n",
       " 0.8542218804359436,\n",
       " 0.855357825756073,\n",
       " 0.8504354357719421,\n",
       " 0.8534646034240723,\n",
       " 0.8538432121276855,\n",
       " 0.8546005487442017,\n",
       " 0.8546005487442017,\n",
       " 0.8481635451316833,\n",
       " 0.855357825756073,\n",
       " 0.8424838781356812,\n",
       " 0.8527073264122009,\n",
       " 0.8568723797798157,\n",
       " 0.8428625464439392,\n",
       " 0.8580083250999451,\n",
       " 0.8568723797798157]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1035b534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We will plot the summary history for the accuracy\n",
    "\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4d13a0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cfb3a5a7a0>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "de8b8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "## We now make predictions and evaluate our model\n",
    "\n",
    "## Using the test set\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a58a618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "## Make confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d74efbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1559,  278],\n",
       "       [  19,  144]], dtype=int64)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix (y_pred, y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "155d3f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8515"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##accuracy\n",
    "\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "23d31781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to get the weights\n",
    "\n",
    "#classifier.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2cce93d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ce59d9ea-4a24-42d9-bfe2-644bf9da0e67/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"ANN_model.pickle\", \"wb\") as ANN_file:\n",
    "    \n",
    "    ANN_file = pickle.dump(model_history, ANN_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e52981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
